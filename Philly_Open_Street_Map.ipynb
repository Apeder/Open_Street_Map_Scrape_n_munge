{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Street Map Scrape, Cleaning and SQL DB Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Analysis - Philadelphia, PA Open Street Map (OSM) XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sample the 500MB XML file to see what data fields are available and how the data are structured between node, way and relation elements. \n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "# Sample 10% of file\n",
    "sample_file_k10 = \"sample10.osm\"\n",
    "\n",
    "# Sample %20\n",
    "sample_file_k5 = \"sample5.osm\"\n",
    "\n",
    "# Sample %30\n",
    "sample_file_k3 = \"sample3.osm\"\n",
    "\n",
    "# whole file\n",
    "osm_file = \"philadelphia_pennsylvania.osm\"\n",
    "\n",
    "# set paramater to take every kth top-level element\n",
    "# k = 10\n",
    "k = 5\n",
    "# k=3\n",
    "\n",
    "# [LXML](http://lxml.de) is definitely faster to read and summarize the OSM XML tree than BeautifulSoup, though \n",
    "# editing and rewriting the tree seemed simpler with bs4. Since the full file is too large to process locally, we'll\n",
    "# sample it to create two test OSM XML files: one with %20 of the elements and one with 33%. \n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags: # Yield only node, way and relation tags\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "# Write every kth 'node', 'way' and 'relation' element to the test file\n",
    "with open(sample_file_k5, 'wb') as output:\n",
    "    output.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write('<osm>\\n  ') \n",
    "    \n",
    "    for i, elem in enumerate(get_element(osm_file)):\n",
    "        if i % k == 0: # When i divided by k leaves remainder 0\n",
    "            output.write(ET.tostring(elem, encoding='utf-8'))\n",
    "    \n",
    "    output.write('</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count each of the root node children's elements. Takes a little over 1 minute to iterate through the full OSM XML file.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def count_level_I_tags(filename):\n",
    "#         import time\n",
    "#         start_time = time.time()\n",
    "        root = ET.parse(filename).getroot()\n",
    "        items = []\n",
    "        for child in root.iter():\n",
    "            tag_name = child.tag\n",
    "            items.append(tag_name)\n",
    "        tags = Counter(items)\n",
    "        return tags\n",
    "#         print(\"--- {}min ---\".format((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'bounds': 1,\n",
       "         'member': 51084,\n",
       "         'nd': 3387554,\n",
       "         'node': 2811847,\n",
       "         'osm': 1,\n",
       "         'relation': 3976,\n",
       "         'tag': 1720896,\n",
       "         'way': 261503})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are over 2.8 million node tags, over 261 thousand way tags and only about 4000 relation tags. There are also \n",
    "# over 1.7 million tags nested below node, way and relation elements.\n",
    "# http://wiki.openstreetmap.org/wiki/OSM_XML\n",
    "\n",
    "# This would make a good chart - top ten tags in the OSM file v. bottom 10\n",
    "\n",
    "# count_level_I_tags('sample10.osm')\n",
    "# count_level_I_tags('sample5.osm')\n",
    "# count_level_I_tags('sample3.osm')\n",
    "count_level_I_tags('philadelphia_pennsylvania.osm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All tags seem to be in order, none floating around where they shouldn't be. \n",
    "def count_orphans(filename):\n",
    "        root = ET.parse(filename).getroot()\n",
    "        items = []\n",
    "        for node in root.findall('tag'):\n",
    "            tag_name = node.get('k')\n",
    "            items.append(tag_name)\n",
    "        orphan_tags = Counter(items)\n",
    "#         return orphan_tags\n",
    "        print len(orphan_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count_orphans(osm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3466"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Have a glance at what the street tags look like - 3466 tags have 'addr:street' attributes\n",
    "soup = BeautifulSoup(open('sample5.osm', \"r+b\"), \"xml\")\n",
    "    \n",
    "street_tags = soup.find_all(\"tag\", attrs={\"k\": \"addr:street\"})\n",
    "\n",
    "len(street_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Total_Node_tags': 3457, 'Tags_Nparent_yes': 6932, 'Tags_Nparent_no': 3475}\n"
     ]
    }
   ],
   "source": [
    "# Even though we found no orphan tags under the root, there may be a few orphan tags with addr:street attributes nested further \n",
    "# down in the XML tree\n",
    "parents = []\n",
    "\n",
    "for tag in street_tags:\n",
    "    par_n = tag.find_parent(\"node\")\n",
    "    par_w = tag.find_parent(\"way\")\n",
    "    parents.append(par_n)\n",
    "    parents.append(par_w)\n",
    "\n",
    "parent_list_nan = filter(lambda x: x==None, parents)\n",
    "\n",
    "rr = len(parents)\n",
    "tt = len(parent_list_nan)\n",
    "tot = rr - tt\n",
    "\n",
    "table = {'Tags_Nparent_yes' : rr, 'Tags_Nparent_no' : tt, 'Total_Node_tags': tot}\n",
    "\n",
    "print table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find all unique tag names amongst the children tags of parent tags 'node', 'way', and 'relation'.\n",
    "# Takes a little over 5 seconds to run over sample_file_k5, about 20% of the dataset. \n",
    "# Takes over 37 seconds on local 2.8 GHz Intel Core i7 with 16 GB flash memory to run over the full OSM file.\n",
    "\n",
    "import pprint\n",
    "import operator\n",
    "\n",
    "def count_tags(filename):\n",
    "        import time\n",
    "        start_time = time.time()\n",
    "        root = ET.parse(filename).getroot()\n",
    "        items = []\n",
    "        for node in root.findall('node/tag'):\n",
    "            tag_name = node.get('k')\n",
    "            items.append(tag_name)\n",
    "#         for way in root.findall('way/tag'):\n",
    "#             tag_name = way.get('k')\n",
    "#             items.append(tag_name)\n",
    "#         for rel in root.findall('relation/tag'):\n",
    "#             tag_name = rel.get('k')\n",
    "#             items.append(tag_name)\n",
    "        all_tags = Counter(items)\n",
    "        tags_dict = dict(all_tags)\n",
    "        tags_rank = sorted(tags_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        print tags_rank[:29]\n",
    "\n",
    "#         print len(items)\n",
    "#         print len(all_tags)\n",
    "#         print(\"--- {} seconds ---\".format((time.time() - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('created_by', 198001), ('highway', 15142), ('name', 12695), ('amenity', 7866), ('addr:street', 7433), ('addr:housenumber', 7284), ('ele', 5987), ('addr:city', 5686), ('gnis:feature_id', 4406), ('power', 4014), ('addr:state', 3477), ('addr:postcode', 3354), ('gnis:created', 3304), ('gnis:county_id', 3183), ('gnis:state_id', 3180), ('source', 3009), ('crossing', 2466), ('railway', 2130), ('shop', 1866), ('building', 1831), ('place', 1630), ('is_in', 1592), ('gnis:ST_num', 1580), ('gnis:County', 1580), ('gnis:County_num', 1580), ('gnis:ST_alpha', 1580), ('gnis:id', 1579), ('gnis:Class', 1579), ('import_uuid', 1578)]\n"
     ]
    }
   ],
   "source": [
    "# Tags with more records will make better sample queries after we port over to SQL. Others are mystifiying. 'PA:ANALGROUP': 1, 'wood', 'surveillance', 'supervised': 43\n",
    "# 'shelter': 11, 'power': 872, 'parking': 252. We have 854 unique tags, many with few entries (percentage under 4 entries?)\n",
    "# SELECT count(), tag FROM table WHERE count(tag) < 5\n",
    "# Suggests a more consistent tagging procedure would greatly improve the map's metadata. \n",
    "# Is ingesting map data from a Google Maps API easier? No. \n",
    "# way and relation tags seem sparser than node tags. \n",
    "# There are 1720896 tags, so none are orphans unattached to a node, way or relation, the OSM XML schema's three \n",
    "# data primitives\n",
    "\n",
    "# Could also scrape http://wiki.openstreetmap.org/wiki/Map_Features to ensure that only recognized tag key-value pairs\n",
    "# can be entered in the dataset as tag elements. At least would be interesting to compare the list below with the list\n",
    "# scraped from OSM sight. With luck, the same fuzzy string matching technique will work on both, and we can clean up the \n",
    "# tags a bit. \n",
    "\n",
    "# Node.'amenity': 1607\n",
    "# 'addr:street': 1500\n",
    "# 'traffic_calming': 38\n",
    "# 'social_facility': 61,\n",
    "# 'public_transport': 46\n",
    "# 'website': 153,\n",
    "\n",
    "# Looks like Tiger has also listed out name bases with more than one word.  If we cleanse and merge these lists, could\n",
    "# we improve our street name matching approach? \n",
    "\n",
    "#          'tiger:name_base_1': 1550,\n",
    "#          'tiger:name_base_2': 171,\n",
    "#          'tiger:name_base_3': 8,\n",
    "\n",
    "# count_tags(sample_file_k10)\n",
    "# count_tags(sample_file_k5)\n",
    "count_tags(osm_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Canonical List of Street Names for Fuzzy String Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two lists of street names from Philly Open Gov weren't cleaned or comprehensive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>SEG_ID</th>\n",
       "      <th>PRE_DIR</th>\n",
       "      <th>NAME</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SUF_DIR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>346</td>\n",
       "      <td>100199.0</td>\n",
       "      <td>S</td>\n",
       "      <td>EIGHTY FOURTH</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>347</td>\n",
       "      <td>100199.0</td>\n",
       "      <td>S</td>\n",
       "      <td>EIGHTY-FOURTH</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>348</td>\n",
       "      <td>100200.0</td>\n",
       "      <td>S</td>\n",
       "      <td>EIGHTY FOURTH</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>349</td>\n",
       "      <td>100200.0</td>\n",
       "      <td>S</td>\n",
       "      <td>EIGHTY-FOURTH</td>\n",
       "      <td>ST</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>350</td>\n",
       "      <td>100206.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RECIRCULATION</td>\n",
       "      <td>RD</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID    SEG_ID PRE_DIR           NAME TYPE  SUF_DIR\n",
       "0       346  100199.0       S  EIGHTY FOURTH   ST      NaN\n",
       "1       347  100199.0       S  EIGHTY-FOURTH   ST      NaN\n",
       "2       348  100200.0       S  EIGHTY FOURTH   ST      NaN\n",
       "3       349  100200.0       S  EIGHTY-FOURTH   ST      NaN\n",
       "4       350  100206.0     NaN  RECIRCULATION   RD      NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create expected list from scraped name strings at http://www.geographic.org/streetview/usa/pa/philadelphia.html\n",
    "# how does it compare to the tiger name attributes in the way objects? Compare all these sets of names? \n",
    "#The first philly gov dataset turns out not to be very useful. \n",
    "import pandas as pd\n",
    "\n",
    "philly_streets_canon = pd.read_csv('http://gis.phila.gov/gisdata/ODP/STR_AliasList.csv')\n",
    "\n",
    "philly_streets_canon.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Coerce variables to string - some Nan values are typed as integers and don't play nicely\n",
    "philly_streets_canon[['NAME', 'TYPE']] = philly_streets_canon[['NAME', 'TYPE']].astype(str)\n",
    "# philly_streets_canon = philly_streets_canon[[philly_streets_canon.NAME.notnull(), philly_streets_canon.TYPE.notnull()]]\n",
    "\n",
    "philly_streets_canon['Type'] = philly_streets_canon['TYPE'].apply(lambda x: x.lower().capitalize())\n",
    "\n",
    "philly_streets_canon['Type'] = philly_streets_canon['Type'].replace(philly_streets_canon.Type.values, \n",
    "                                            [mapping.get(word, word) for word in philly_streets_canon.Type.values])\n",
    "\n",
    "# philly_streets_canon['full_name'] = philly_streets_canon['full_name'].replace(philly_streets_canon.full_name.values, \n",
    "#                                       [mapping.get(word, word) for word in philly_streets_canon.full_name.values])\n",
    "\n",
    "# Some missing values need to be taken out\n",
    "# philly_streets_canon['TYPE'][9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "philly_streets_canon['full_name'] = philly_streets_canon[['NAME', 'Type']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "philly_streets_canon['full_name'] = philly_streets_canon['full_name'].apply(lambda x: x.capitalize())\n",
    "\n",
    "len(philly_streets_canon['full_name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Recirculation road', 'I 95 nan', 'I95 nan', 'I 95 expressway',\n",
       "       'I95 expressway', '291 highway', 'Pa 291 highway',\n",
       "       'Route 291 highway', 'State highway 291 highway', 'I 95 ramp',\n",
       "       'I95 ramp', '95 ramp nan', '95 rmp nan', '291 nan', 'I291 nan',\n",
       "       'Route 291 nan', 'I 76 nan', 'I 76 street'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Mispellings here are also not great:\n",
    "\n",
    "# ((\\b[tfsen].+y\\b)-? ?(\\b[tfsen].+[thrdstnd]\\b) street)\n",
    "# ([tfsen].+y) ?-?(?P<tens>[tfsen].+[th|rd|st|nd])|(?P=tens) street\n",
    "\n",
    "#Replace with a range of numbers paired with 'Street' 1-90, 64-79 weird little avenues right at the edge of Cheltenham\n",
    "numbered_streets = re.compile(r'(\\b[\\dtzfsen].+[thndo]\\b street)', re.IGNORECASE)\n",
    "\n",
    "philly_streets_canon['full_name'] = philly_streets_canon['full_name'].replace(numbered_streets,'')\n",
    "\n",
    "philly_streets_canon['full_name'].unique()[:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Street', 'Road', 'Nan', 'Expressway', 'Highway', 'Ramp', 'Parkway', 'Drive', 'Boulevard', 'Avenue', 'Way', 'Terrace', 'Court', 'Trail', 'Square', 'Place', 'Exit', 'Tunnel', 'Row', 'Lane', 'Walk', 'Crescent', 'Circle']\n"
     ]
    }
   ],
   "source": [
    "philly_street_type_canon = list(philly_streets_canon['Type'].unique())\n",
    "\n",
    "# philly_street_type_canon = philly_street_type_canon.remove('Nan')\n",
    "\n",
    "print philly_street_type_canon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>ALIAS</th>\n",
       "      <th>ADDRESS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>219</td>\n",
       "      <td>Allen M Sterne School</td>\n",
       "      <td>1655 UNITY ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220</td>\n",
       "      <td>Allens La Art Center</td>\n",
       "      <td>601 W ALLENS LN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221</td>\n",
       "      <td>Allens Lane Park</td>\n",
       "      <td>200 NIPPON ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222</td>\n",
       "      <td>Allens Lane Sta</td>\n",
       "      <td>200 NIPPON ST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>223</td>\n",
       "      <td>Allens Lane Station</td>\n",
       "      <td>200 NIPPON ST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID                  ALIAS          ADDRESS\n",
       "0       219  Allen M Sterne School    1655 UNITY ST\n",
       "1       220   Allens La Art Center  601 W ALLENS LN\n",
       "2       221       Allens Lane Park    200 NIPPON ST\n",
       "3       222        Allens Lane Sta    200 NIPPON ST\n",
       "4       223    Allens Lane Station    200 NIPPON ST"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try another way by getting all the unique names from a list of placenames in Philly. Still no guarantee it's \n",
    "# comprehensive, even though the file is provided by Philadelphia.gov's open data project. https://www.opendataphilly.org/dataset/street-place-names/resource/ed10ab8b-e998-4853-b440-81df22c39bfc\n",
    "psc = pd.read_csv('http://gis.phila.gov/gisdata/ODP/STR_PlaceNames.csv')\n",
    "psc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Unity Street', 'West Allens Lane', 'Nippon Street', 'Cecil B Moore Avenue', 'Walnut Street', 'Erdrick Street', 'South Broad Street', 'Locust Walk', 'North Independence Ml West', 'North Broad Street', 'Red Lion Road', 'Chestnut Street', 'North 15th Street', 'Pine Street', 'South 16th Street', 'Locust Street', 'Pattison Avenue', 'North Independence Ml West', 'South 48th Street', 'South 23rd Street']\n"
     ]
    }
   ],
   "source": [
    "# A list like this would be good to restrict form input data for Open Street Map. \n",
    "\n",
    "psc['ADDRESS'] = psc['ADDRESS'].astype(str)\n",
    "\n",
    "psc['Address'] = psc['ADDRESS'].replace(re.compile(r'^\\d+(?!th|rd|st|nd)'), '').apply(lambda x: x.lower())\n",
    "\n",
    "streets = list(psc['Address'].unique())\n",
    "\n",
    "for idx, s in enumerate(streets):\n",
    "    words = s.split()\n",
    "    words = [x.capitalize() for x in words]\n",
    "    clean = ' '.join(str(mapping.get(word, word)) for word in words)\n",
    "    streets[idx] = clean\n",
    "\n",
    "print streets[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1213"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This seems too low, think this file is only for streets that may have multiple aliases. \n",
    "len(streets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fortunately, the US Census TIGER data includes street names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Though the addr:street attributes in the node tags contain errors, the ways, imported from the US Census' TIGER \n",
    "# dataset, are cleaner. We can use these to build a canonical reference list of street name strings. \n",
    "<way changeset=\"37014829\" id=\"43117631\" timestamp=\"2016-02-05T08:40:51Z\" uid=\"3057995\" user=\"oini\" version=\"11\">\n",
    "  <nd ref=\"110421617\"/>\n",
    "  <nd ref=\"2906080683\"/>\n",
    "  <tag k=\"name\" v=\"West Girard Avenue\"/>\n",
    "  <tag k=\"layer\" v=\"1\"/>\n",
    "  <tag k=\"bridge\" v=\"yes\"/>\n",
    "  <tag k=\"highway\" v=\"secondary\"/>\n",
    "  <tag k=\"tiger:cfcc\" v=\"A21\"/>\n",
    "  <tag k=\"ref:penndot\" v=\"SR2008\"/>\n",
    "  <tag k=\"tiger:zip_left\" v=\"19131\"/>\n",
    "  <tag k=\"tiger:name_base\" v=\"Girard\"/>\n",
    "  <tag k=\"tiger:name_type\" v=\"Ave\"/>\n",
    "  <tag k=\"tiger:zip_right\" v=\"19104\"/>\n",
    "  <tag k=\"tiger:name_base_1\" v=\"United States Highway 30\"/>\n",
    "  <tag k=\"old_ref_legislative\" v=\"67301\"/>\n",
    "  <tag k=\"tiger:name_direction_prefix\" v=\"W\"/>\n",
    " </way>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sometimes a 'name' attribute is the street name, other times it's the name of a location or establishment \n",
    "<way changeset=\"10677130\" id=\"150255661\" timestamp=\"2012-02-13T20:23:59Z\" uid=\"594684\" user=\"kumpel75\" version=\"1\">\n",
    "  <nd ref=\"1631799891\"/>\n",
    "  <nd ref=\"1631799894\"/>\n",
    "  <nd ref=\"1631799920\"/>\n",
    "  <nd ref=\"1631799922\"/>\n",
    "  <nd ref=\"1631799962\"/>\n",
    "  <nd ref=\"1631799959\"/>\n",
    "  <nd ref=\"1631799945\"/>\n",
    "  <nd ref=\"1631799914\"/>\n",
    "  <nd ref=\"1631799891\"/>\n",
    "  <tag k=\"name\" v=\"Red Lion Diner\"/>\n",
    "  <tag k=\"building\" v=\"restaurant\"/>\n",
    "  <tag k=\"addr:street\" v=\"US and US Streets\"/>\n",
    "  <tag k=\"addr:postcode\" v=\"08088\"/>\n",
    "  <tag k=\"addr:housename\" v=\"Red Lion Diner\"/>\n",
    " </way>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "#Let's compare how many unique street names we have in the osm file\n",
    "\n",
    "street_soup = BeautifulSoup(open('philadelphia_pennsylvania.osm', \"r+b\"), \"xml\")\n",
    "\n",
    "street_ns = []\n",
    "# dirs = []\n",
    "# types = []\n",
    "\n",
    "#Could compare the address with the name in the way tag, or just replace it? Need to get tiger name bases for 1 and 2 \n",
    "#word bases \n",
    "street_names_tig = street_soup.find_all(\"tag\", attrs={\"k\": \"tiger:name_base\"})\n",
    "for i in street_names_tig:\n",
    "    street_ns.append(i['v'])\n",
    "\n",
    "# street_directions = street_soup.find_all(\"tag\", attrs={\"k\": \"tiger:name_direction_prefix\"})\n",
    "# for i in street_directions:\n",
    "#     dirs.append(i['v'])\n",
    "\n",
    "# type_types = street_soup.find_all(\"tag\", attrs={\"k\": \"tiger:name_type\"})\n",
    "# for i in type_types:\n",
    "#     types.append(i['v'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collect all the name attributes in the tags nested under way elements. \n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "waynames = []\n",
    "\n",
    "root = ET.parse(osm_file).getroot()\n",
    "\n",
    "def is_street(tag):\n",
    "    return (tag.attrib['k'] == \"name\")\n",
    "\n",
    "for node in root.findall('way/tag'):\n",
    "    if is_street(node):\n",
    "        waynames.append(node.attrib['v'])\n",
    "            \n",
    "# street_way_names = street_soup.find_all(\"tag\", attrs={\"k\": \"name\"})\n",
    "# for i in street_way_names:\n",
    "#     waynames.append(i['v'])\n",
    "    \n",
    "d = {'full_name': waynames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Seaport Drive',\n",
       " 'Industrial Highway',\n",
       " 'Morton Avenue',\n",
       " 'Bullens Lane',\n",
       " 'Chester Road',\n",
       " '9th Street',\n",
       " 'Chestnut Street',\n",
       " 'Schuylkill River',\n",
       " 'Pennsylvania Turnpike',\n",
       " 'Valley Avenue',\n",
       " 'North 1st Road',\n",
       " 'South Liberty Street',\n",
       " 'White Horse Pike',\n",
       " 'North Street',\n",
       " 'Linda Avenue',\n",
       " 'Batsto Fireline Road',\n",
       " 'Virginia Avenue',\n",
       " 'North Packard Street',\n",
       " 'Tomocomo Drive']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# s is a list of the base names, and w is a list of full street name strings, with any house numbers stripped from the beginning.\n",
    "\n",
    "import pandas as pd\n",
    "# s = pd.Series(d['base_name']).unique()\n",
    "# t = pd.Series(d['type']).unique()\n",
    "numbers = re.compile(r'^\\d+(?!th|rd|st|nd)')\n",
    "w = list(pd.Series(d['full_name']).str.replace('^\\d+(?!th|rd|st|nd)', '').unique())\n",
    "w[:19]\n",
    "# w = w.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15284"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we at least have a list of all the basenames, of which there are 15284.  We don't have the type endings or \n",
    "# directional prefixes, though.  At least we know how many different street names there are. Might also be good to \n",
    "#pull the highways names from here. u'Mantua;Harrison' some strange items with semi-colons\n",
    "\n",
    "# u'Pederson' What's up with this? There are some clearly problematic items on the list, though they may or may not \n",
    "# cause a problem for approximate string matching. Also appear to be clustered at the end of the list.\n",
    "\n",
    "# u'Norfolk Southern Railway:Pennsylvania Railroad', u'Belmont;Green', u'United States Highway 1; Lincoln', \n",
    "# u'Mantua;Harrison', u'Reading Railroad:Septa Railroad', u'Baltimore and Ohio Railroad:Norfolk Southern Railway', \n",
    "# u'Franklin:Hampton', u'State Route 68; State Route 68; State Route 68A; State Route 68; State Route 68', \n",
    "# u'United States Highway 206;Old York', u'Perry; Lincoln', u'Norfolk Southern Railway; Csx Railway; Conrail Railroad', \n",
    "# u'Township Line;Big Oak', u'Market:United States Highway 13 (Bus)', u'Coursey; College', u'I-295:I-76', u'Early; Davis',\n",
    "# u'of the Arts', u'\\x7f\\x7fBeech', u'Bridge; Main', Spring:Pond View', u'Cypress:Longacre', u'Delmar;84th', \n",
    "# u'New Jersey Transit:Penn Central Railroad; Conrail Railroad'\n",
    "\n",
    "# philly_street_name_canon = list(s)\n",
    "# print philly_street_name_canon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15284"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(philly_street_name_canon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unfortunately, the Tiger name bases may not be needed if the full name strings work well enough. We'll write the base names to disk\n",
    "# just in case they're needed another time.\n",
    "import csv\n",
    "\n",
    "with open('./philly_street_base_names_canon.txt', 'wb') as basesphilly:\n",
    "    for item in unicode(philly_street_name_canon):\n",
    "        basesphilly.write(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at the full name strings to see if this list of full name strings can be used as a canonical reference for \n",
    "# fuzzy string matching\n",
    "type(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40943"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Seaport Drive', 'Industrial Highway', 'Morton Avenue', 'Bullens Lane', 'Chester Road', '9th Street', 'Chestnut Street', 'Schuylkill River', 'Pennsylvania Turnpike', 'Valley Avenue', 'North 1st Road', 'South Liberty Street', 'White Horse Pike', 'North Street', 'Linda Avenue', 'Batsto Fireline Road', 'Virginia Avenue', 'North Packard Street', 'Tomocomo Drive']\n"
     ]
    }
   ],
   "source": [
    "#Also needs to be cleaned with mapping for Rd, Dr\n",
    "print list(w)[:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Street',\n",
       " 'Streets',\n",
       " 'Avenue',\n",
       " 'Boulevard',\n",
       " 'Drive',\n",
       " 'Court',\n",
       " 'Place',\n",
       " 'Square',\n",
       " 'Lane',\n",
       " 'Road',\n",
       " 'Bypass',\n",
       " 'Trail',\n",
       " 'Parkway',\n",
       " 'Commons',\n",
       " 'Pike',\n",
       " 'Alley',\n",
       " 'Circle',\n",
       " 'East',\n",
       " 'North',\n",
       " 'South',\n",
       " 'West',\n",
       " 'Crossing',\n",
       " 'Extension',\n",
       " 'Highway',\n",
       " 'Plaza',\n",
       " 'Terrace',\n",
       " 'Walk',\n",
       " 'Way',\n",
       " 'Run',\n",
       " 'Tunnel',\n",
       " 'Broadway',\n",
       " 'Park',\n",
       " 'Close']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean out the 'name' tags that refer to placenames rather than street names by filtering with regex to ensure that all strings\n",
    "# terminate with an expected ending. \n",
    "street_names_list = w\n",
    "\n",
    "street_yes = re.compile(r'(\\bstreets?|avenue|boulevard|drive|court|place|square|lane|road|trail|parkway|commons|pike|alley|circle|east|north|south|west|extension|highway|plaza|terrace|walk|run|tunnel|broadway|close|park|crossing|bypass\\b)$', re.IGNORECASE)\n",
    "\n",
    "clean_street_name_canon = []\n",
    "\n",
    "for idx, i in enumerate(street_names_list):\n",
    "    match = street_yes.search(i)\n",
    "    if match: \n",
    "        clean_street_name_canon.append(i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31489"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clean_street_name_canon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Road', 5978), ('Drive', 4785), ('Avenue', 4315), ('Lane', 3902), ('Street', 3593), ('Court', 3289), ('Circle', 1251), ('Place', 1170), ('Boulevard', 459), ('Park', 453), ('Terrace', 428), ('Alley', 364), ('Trail', 318), ('Run', 196), ('West', 124)]\n"
     ]
    }
   ],
   "source": [
    "# 'Pepperoncini': 1, ? What is going on with even the Tiger names?! Over 2000 different endings. \n",
    "from collections import Counter\n",
    "endings = []\n",
    "\n",
    "for street in clean_street_name_canon:\n",
    "    x = street.split(' ')\n",
    "#     y = len(x)\n",
    "    endings.append(x[-1])\n",
    "    \n",
    "street_ends = dict(Counter(endings))\n",
    "st_ends_rank = sorted(street_ends.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print st_ends_rank[:15] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(pd.Series(endings).unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Seaport Drive',\n",
       " 'Industrial Highway',\n",
       " 'Morton Avenue',\n",
       " 'Bullens Lane',\n",
       " 'Chester Road',\n",
       " '9th Street',\n",
       " 'Chestnut Street',\n",
       " 'Pennsylvania Turnpike',\n",
       " 'Valley Avenue',\n",
       " 'North 1st Road',\n",
       " 'South Liberty Street',\n",
       " 'White Horse Pike',\n",
       " 'North Street',\n",
       " 'Linda Avenue',\n",
       " 'Batsto Fireline Road',\n",
       " 'Virginia Avenue',\n",
       " 'North Packard Street',\n",
       " 'Tomocomo Drive',\n",
       " 'North Union Road']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#15000 basenames with 31489 total combinations of directional prefixes and road type suffixes makes sense. \n",
    "#Using this as a list of choices, we can employ approximate (fuzzy) string matching to test if street name strings\n",
    "# match list items.  We can adjust matches based on Levenstein Distance, which calculates how many characters \n",
    "# strings share as a numerical matching score. The same logic could be used via Django to reject input to the addr:name\n",
    "#attribute\n",
    "\n",
    "# Using the larger Census TIGER National Road dataset could work for n-gram matching, though it would need to be hosted on S3 and \n",
    "# processing would need to be done via Spark on AWS EMR or Databricks. \n",
    "\n",
    "clean_street_name_canon[:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can use this as a list of choices for fuzzy string matching on the full names in the addr:street attributes of tags\n",
    "import csv\n",
    "\n",
    "with open('./philly_street_full_names_canon.csv', 'w') as streetsphilly:\n",
    "    wr = csv.writer(streetsphilly, quoting=csv.QUOTE_ALL)\n",
    "    wr.writerow(clean_street_name_canon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning OSM File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Audit Function to Review Street Names in OSM Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "import csv\n",
    "\n",
    "# Matches words beginning with any non-whitespace character that repeats >1 time, possibly ends with a period and \n",
    "# occurs at the end of a line. \n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE) \n",
    "\n",
    "# Search through a list of strings to confirm they terminate with items in the 'expected' list.\n",
    "# If strings end with an item that's not a member of 'expected,' add the group of strings surrounding this item to the\n",
    "# list 'street_types'\n",
    "\n",
    "expected = [\"Street\", \"Streets\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \"Bypass\",\n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Pike\", \"Alley\", \"Circle\", \"East\", \"North\", \"South\", \"West\", \"Crossing\",\n",
    "            \"Extension\", \"Highway\", \"Plaza\", \"Terrace\", \"Walk\", \"Way\", \"Run\", \"Tunnel\", \"Broadway\", \"Park\", \"Close\"]\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "# Audit an osm file and return a dictionary of strings that don't terminate with any of the words in the expected list \n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osm_file, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'206': {'US 70 & US 206'},\n",
       "             '33': {'Route 33'},\n",
       "             '37th': {'N 37th'},\n",
       "             '43rd': {'N 43rd'},\n",
       "             '446-1234': {'1 Brookline BlvdHavertown, PA 19083(610) 446-1234'},\n",
       "             '5': {'West Girard Avenue, 5'},\n",
       "             '70': {'NJ 70', 'US 70'},\n",
       "             '73': {'New Jersey 73'},\n",
       "             '80': {'N Lewis RD Unit #80'},\n",
       "             'Ave': {'Aramingo Ave',\n",
       "              'Cottman Ave',\n",
       "              'Devon St & Mt. Pleasant Ave',\n",
       "              'E. Mt Airy Ave',\n",
       "              'Fairmount Ave',\n",
       "              'Fort Washington Ave',\n",
       "              'Frankford Ave',\n",
       "              'Germantown Ave',\n",
       "              'Grays Ave',\n",
       "              'Hirst Ave',\n",
       "              'Montgomery Ave',\n",
       "              'Park Ave',\n",
       "              'Parkway Ave',\n",
       "              'S Clinton Ave',\n",
       "              'Stenton Ave',\n",
       "              'West Girard Ave'},\n",
       "             'Ave.': {'Bonny Brook Ave.',\n",
       "              'East Butler Ave.',\n",
       "              'West Butler Ave.'},\n",
       "             'Bigler': {'Bigler'},\n",
       "             'Blvd': {'Centennial Blvd',\n",
       "              'Garden Golf Blvd',\n",
       "              'Hearthstone Blvd',\n",
       "              'Nassau Parl Blvd'},\n",
       "             'Center': {'Town Center'},\n",
       "             'Chestnut': {'Chestnut'},\n",
       "             'Cir': {'Woodfield Cir'},\n",
       "             'Dr': {'Revere Dr', \"Tommy's Meadow Dr\"},\n",
       "             'Ln': {'Hartford Ln', 'Simpkins Ln'},\n",
       "             'Mallon': {'Mallon'},\n",
       "             'Moore': {'Cecil B. Moore'},\n",
       "             'NJ-73': {'NJ-73'},\n",
       "             'PA': {'E Lincoln HwyLanghorne, PA'},\n",
       "             'PIke': {'Princeton PIke'},\n",
       "             'Rd': {\"Arney's Mount Rd\",\n",
       "              'Bristol Rd',\n",
       "              'Calcon Hook Rd',\n",
       "              'Clements Bridge Rd',\n",
       "              'Dilworthtown Rd',\n",
       "              'Grove Rd',\n",
       "              'Hulmeville Rd',\n",
       "              'Hurffville  Rd',\n",
       "              'Hurffville Rd',\n",
       "              'Meetinghouse Rd',\n",
       "              'Old Cuthbert Rd',\n",
       "              'South Easton Rd',\n",
       "              'W Cohawkin Rd',\n",
       "              'York Rd'},\n",
       "             'Rd.': {'N. Lewis Rd.'},\n",
       "             'ST': {'S 6TH ST'},\n",
       "             'Spruce': {'Spruce'},\n",
       "             'St': {'Carson St',\n",
       "              'Center St',\n",
       "              'Dickinson St',\n",
       "              'E Hampton St',\n",
       "              'E Luzerne St',\n",
       "              'E State St',\n",
       "              'Green St',\n",
       "              'Market St',\n",
       "              'N 4th St',\n",
       "              'N 5th St',\n",
       "              'N Broad St',\n",
       "              'N Main St',\n",
       "              'North Front St',\n",
       "              'S 20th St',\n",
       "              'S 22nd St',\n",
       "              'S 24th St',\n",
       "              'S 41st St',\n",
       "              'S Broad St',\n",
       "              'Spring Garden St'},\n",
       "             'St.': {'Diamond St.',\n",
       "              'E. State St.',\n",
       "              'N 24th St.',\n",
       "              'S. 15th St.',\n",
       "              'South Broad St.'},\n",
       "             'Vine': {'12th and Vine'},\n",
       "             'Warren': {'Warren'},\n",
       "             'ave': {'michigan ave'},\n",
       "             'avenue': {'Ohio avenue'},\n",
       "             'rd': {'Lawrenceville rd'},\n",
       "             'st': {'centre st',\n",
       "              'clay st',\n",
       "              'e front st',\n",
       "              'e state st',\n",
       "              'jackson st',\n",
       "              'market st',\n",
       "              'mercer st',\n",
       "              'pear st',\n",
       "              's 3rd st',\n",
       "              's broad st',\n",
       "              's montgomery st',\n",
       "              's warren st',\n",
       "              'w state st'},\n",
       "             'street': {'tilton street'}})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit(sample_file_k5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'1': {'Route 1'},\n",
       "             '111': {'South Clinton Avenue Ste. 111'},\n",
       "             '13': {'W Main St #13'},\n",
       "             '168': {'Marlton Pike East Ste. 168'},\n",
       "             '19047': {'200 Manor Ave. Langhorne, PA 19047',\n",
       "              '2245 E. Lincoln Hwy, Langhorne, PA 19047',\n",
       "              '2275 E Lincoln Hwy, Langhorne, PA 19047',\n",
       "              '2300  East Lincoln Highway, Pennsylvania 19047'},\n",
       "             '19067': {'East Trenton Avenue Morrisville, PA 19067'},\n",
       "             '206': {'US 206', 'US 70 & US 206'},\n",
       "             '33': {'Route 33'},\n",
       "             '37th': {'N 37th'},\n",
       "             '38': {'New Jersey 38', 'New Jersey Route 38', 'Route 38'},\n",
       "             '39th': {'N 39th'},\n",
       "             '40': {'1140 US Highway 40', 'Rt 40'},\n",
       "             '4080': {'4080'},\n",
       "             '41st': {'S. 41st'},\n",
       "             '43rd': {'N 43rd'},\n",
       "             '446-1234': {'1 Brookline BlvdHavertown, PA 19083(610) 446-1234'},\n",
       "             '452': {'Market Street; Pennsylvania Route 452',\n",
       "              'Pennel Road; Pennsylvania Route 452'},\n",
       "             '5': {'West Girard Avenue, 5'},\n",
       "             '53rd': {'N 53rd'},\n",
       "             '611': {'Easton Road Route 611'},\n",
       "             '70': {'NJ 70', 'US 70'},\n",
       "             '73': {'NJ 73', 'New Jersey 73', 'North Route 73', 'Route 73'},\n",
       "             '80': {'N Lewis RD Unit #80'},\n",
       "             '902': {'Chestnut Street #902'},\n",
       "             'AVE': {'EDGMONT AVE'},\n",
       "             'Atreet': {'Arch Atreet'},\n",
       "             'Ave': {'517 W Girard Ave',\n",
       "              '72nd Ave and Orgontz Ave',\n",
       "              '8401 Frankford Ave',\n",
       "              'Alden Ave',\n",
       "              'Aramingo Ave',\n",
       "              'Baltimore Ave',\n",
       "              'Bishop Ave, Clifton Ave',\n",
       "              'Bryn Mawr Ave',\n",
       "              'Chester Ave',\n",
       "              'Constitution Ave',\n",
       "              'Cottman Ave',\n",
       "              'Devon St & Mt. Pleasant Ave',\n",
       "              'E Butler Ave',\n",
       "              'E Lancaster Ave',\n",
       "              'E. Mt Airy Ave',\n",
       "              'East Lancaster Ave',\n",
       "              'East Wadsworth Ave',\n",
       "              'Essington Ave',\n",
       "              'Fairmount Ave',\n",
       "              'Fort Washington Ave',\n",
       "              'Frankford Ave',\n",
       "              'Germantown Ave',\n",
       "              'Grant Ave',\n",
       "              'Grays Ave',\n",
       "              'Hirst Ave',\n",
       "              'Lancaster Ave',\n",
       "              'Montgomery Ave',\n",
       "              'Mt.Ephraim Ave',\n",
       "              'N Olden Ave',\n",
       "              'Park Ave',\n",
       "              'Parkway Ave',\n",
       "              'Pennington Ave',\n",
       "              'Pennsylvania Ave',\n",
       "              'Penrose Ave',\n",
       "              'Philmont Ave',\n",
       "              'Rising Sun Ave',\n",
       "              'S Clinton Ave',\n",
       "              'S Washington Ave',\n",
       "              'S. Clinton Ave',\n",
       "              'Sharon Ave',\n",
       "              'Sloan Ave',\n",
       "              'Stenton Ave',\n",
       "              'Summit Ave',\n",
       "              'Washington Ave',\n",
       "              'West Butler Ave',\n",
       "              'West Girard Ave',\n",
       "              'West Glenside Ave',\n",
       "              'West Huntington Ave',\n",
       "              'West Mermaid Lane and Germantown Ave',\n",
       "              'West Montgomery Ave',\n",
       "              'West Trenton Ave'},\n",
       "             'Ave.': {'Aramingo Ave.',\n",
       "              'Baltimore Ave.',\n",
       "              'Bonny Brook Ave.',\n",
       "              'East Butler Ave.',\n",
       "              'Germantown Ave.',\n",
       "              'Morton Ave.',\n",
       "              'Station Ave.',\n",
       "              'Taylor Ave.',\n",
       "              'West Butler Ave.'},\n",
       "             'Bigler': {'Bigler'},\n",
       "             'Blvd': {'Brookline Blvd',\n",
       "              'Centennial Blvd',\n",
       "              'Floral Vale Blvd',\n",
       "              'Garden Gold Blvd',\n",
       "              'Garden Golf Blvd',\n",
       "              'Hearthstone Blvd',\n",
       "              'Nassau Park Blvd',\n",
       "              'Nassau Parl Blvd',\n",
       "              'S Christopher Columbus Blvd',\n",
       "              'Shannondell Blvd'},\n",
       "             'Blvd.': {'Brookline Blvd.'},\n",
       "             'Broadway': {'373 North Broadway',\n",
       "              'North Broadway',\n",
       "              'South Broadway'},\n",
       "             'Brown': {'N 37th & Brown'},\n",
       "             'Bypass': {'Pemberton Bypass'},\n",
       "             'Center': {'Town Center'},\n",
       "             'Chestnut': {'Chestnut'},\n",
       "             'Chippendale': {'Chippendale'},\n",
       "             'Cir': {'Woodfield Cir'},\n",
       "             'Close': {'Heaver Close'},\n",
       "             'Cricket': {'Cricket'},\n",
       "             'Crossing': {'Painters Crossing'},\n",
       "             'Ct': {'Portsmouth Ct'},\n",
       "             'D102': {'Henry Ave #D102'},\n",
       "             'Dr': {'Deerpath Dr',\n",
       "              'Merrill Lynch Dr',\n",
       "              'Revere Dr',\n",
       "              \"Tommy's Meadow Dr\"},\n",
       "             'E': {'NJ-70 E'},\n",
       "             'Front': {'S Front'},\n",
       "             'Garden': {'Spring Garden'},\n",
       "             'Greene': {'Greene'},\n",
       "             'Haverford': {'Haverford'},\n",
       "             'Hook': {'Calcon Hook'},\n",
       "             'Hutchinson': {'North Hutchinson'},\n",
       "             'Hwy': {'Harding Hwy'},\n",
       "             'Ln': {'Hartford Ln', 'Patricia Ln', 'Simpkins Ln'},\n",
       "             'Mallon': {'Mallon'},\n",
       "             'Maple': {'South Maple'},\n",
       "             'Market': {'Market'},\n",
       "             'Master': {'15th and Master'},\n",
       "             'Moore': {'Cecil B. Moore'},\n",
       "             'NJ-73': {'NJ-73'},\n",
       "             'Nixon': {'Shawmont & Nixon'},\n",
       "             'PA': {'Baltimore Pike, Springfield, PA',\n",
       "              'E Lincoln HwyLanghorne, PA',\n",
       "              'E. Lincoln Highway Langhore, PA',\n",
       "              'Saxer Ave, Springfield, PA'},\n",
       "             'PA.': {'Trenton Rd - Levittown, PA.'},\n",
       "             'PIke': {'Princeton PIke'},\n",
       "             'Park': {'Falsoa Park'},\n",
       "             'Parrish': {'Parrish'},\n",
       "             'Preston': {'N Preston'},\n",
       "             'ROAD': {'DAVISVILLE ROAD', 'TERWOOD ROAD', 'TOWNSHIP LINE ROAD'},\n",
       "             'Rd': {'22 Centerton Rd',\n",
       "              '24 Centerton Rd',\n",
       "              '40 Centerton Rd',\n",
       "              '50 Centerton Rd',\n",
       "              '52 Centerton Rd',\n",
       "              '58 Centerton Rd',\n",
       "              '62 Centerton Rd',\n",
       "              '66 Centerton Rd',\n",
       "              '70 Centerton Rd',\n",
       "              'Abrams Mill Rd',\n",
       "              'Anderson Rd',\n",
       "              \"Arney's Mount Rd\",\n",
       "              'Barren Hill Rd',\n",
       "              'Bristol Rd',\n",
       "              'Calcon Hook Rd',\n",
       "              'Church Rd',\n",
       "              'Clements Bridge Rd',\n",
       "              'Cross Keys Rd',\n",
       "              'Darby Rd',\n",
       "              'Deptford Center Rd',\n",
       "              'Dilworthtown Rd',\n",
       "              'Durham Rd',\n",
       "              'E County Line Rd',\n",
       "              'Easton Rd',\n",
       "              'Edison Furlong Rd',\n",
       "              'Evesham Rd',\n",
       "              'Grove Rd',\n",
       "              'Haddonfield Rd',\n",
       "              'Hulmeville Rd',\n",
       "              'Hurffville  Rd',\n",
       "              'Hurffville Rd',\n",
       "              'Kimberton Rd',\n",
       "              'King Rd',\n",
       "              'Lincoln Mill Rd',\n",
       "              'Meetinghouse Rd',\n",
       "              'N Providence Rd',\n",
       "              'Old Cuthbert Rd',\n",
       "              'S Easton Rd',\n",
       "              'Schuylkill Rd',\n",
       "              'South Easton Rd',\n",
       "              'Stokes Rd',\n",
       "              'Valley Rd',\n",
       "              'W Cohawkin Rd',\n",
       "              'York Rd'},\n",
       "             'Rd.': {'Clements Bridge Rd.',\n",
       "              'Kagey Rd.',\n",
       "              'N. Lewis Rd.',\n",
       "              'North Lewis Rd.',\n",
       "              'S. Chester Rd.',\n",
       "              'W. Street Rd.',\n",
       "              'Wistar Rd.',\n",
       "              'York Rd.'},\n",
       "             'Reno': {'North 50th Street & Reno'},\n",
       "             'Run': {'Autumn River Run', 'Pheasant Run'},\n",
       "             'S': {'Route 73 S'},\n",
       "             'ST': {'S 6TH ST'},\n",
       "             'Salina': {'Salina'},\n",
       "             'Sheffield': {'Sheffield'},\n",
       "             'Sloan': {'Sloan'},\n",
       "             'Spruce': {'Spruce'},\n",
       "             'Sreet': {'Bridge Sreet'},\n",
       "             'Sstreet': {'South 9th Sstreet'},\n",
       "             'St': {'46th and Market St',\n",
       "              '507 E Tulpehocken St',\n",
       "              'Baring St',\n",
       "              'Bush St',\n",
       "              'Carson St',\n",
       "              'Center St',\n",
       "              'Chestnut St',\n",
       "              'Coates St',\n",
       "              'Cooper St',\n",
       "              'Dickinson St',\n",
       "              'E Hampton St',\n",
       "              'E Hector St',\n",
       "              'E Luzerne St',\n",
       "              'E Penn St',\n",
       "              'E State St',\n",
       "              'E Wingohocking St',\n",
       "              'E. Passyunk Ave and Kauffman St',\n",
       "              'Federal St',\n",
       "              'Front St & Tasker St',\n",
       "              'Green St',\n",
       "              'Johnston St',\n",
       "              'Market St',\n",
       "              'McKean St',\n",
       "              'N 4th St',\n",
       "              'N 5th St',\n",
       "              'N 6th St',\n",
       "              'N Broad St',\n",
       "              'N Gratz St',\n",
       "              'N Main St',\n",
       "              'North Broad St',\n",
       "              'North Front St',\n",
       "              'Quarry St',\n",
       "              'Race St',\n",
       "              'Ranstead St',\n",
       "              'Rhawn St',\n",
       "              'S 19th St',\n",
       "              'S 20th St',\n",
       "              'S 22nd St',\n",
       "              'S 24th St',\n",
       "              'S 28th St',\n",
       "              'S 3rd St',\n",
       "              'S 41st St',\n",
       "              'S 47th St',\n",
       "              'S 4th St',\n",
       "              'S 50th St',\n",
       "              'S Broad St',\n",
       "              'S Main St',\n",
       "              'S Norwood St',\n",
       "              'S Warren St',\n",
       "              'South 40th St',\n",
       "              'South Bancroft St',\n",
       "              'South St',\n",
       "              'South St Bernard St',\n",
       "              'Spring Garden St',\n",
       "              'St John St',\n",
       "              'Starr St',\n",
       "              'W State St',\n",
       "              'Walnut St',\n",
       "              'Washington St',\n",
       "              'West Main St'},\n",
       "             'St.': {'12th St.',\n",
       "              'Almond St.',\n",
       "              'Diamond St.',\n",
       "              'E. State St.',\n",
       "              'Mt. Pleasant Ave, Devon St, Sprague St.',\n",
       "              'N 24th St.',\n",
       "              'S. 15th St.',\n",
       "              'S. 40th St.',\n",
       "              'South Broad St.',\n",
       "              'W. State St.'},\n",
       "             'Steet': {'South 18th Steet'},\n",
       "             'Stiles': {'16th and Stiles'},\n",
       "             'StreetPhiladelphia': {'117 South 18th StreetPhiladelphia'},\n",
       "             'Sts.': {'1st and Seneca Sts.'},\n",
       "             'Sycamore': {'North Sycamore'},\n",
       "             'Thompson': {'Sletcher and Thompson'},\n",
       "             'Vine': {'12th and Vine'},\n",
       "             'W': {'NJ 70 W'},\n",
       "             'W5': {'Presidential Blvd, Ste W5'},\n",
       "             'Warminster': {'Warminster'},\n",
       "             'Warren': {'Warren'},\n",
       "             'al': {'pullen al'},\n",
       "             'ave': {'Ridge ave',\n",
       "              'and 1891 brunswick ave',\n",
       "              'hillcrest ave',\n",
       "              'michigan ave'},\n",
       "             'avenue': {'Ohio avenue'},\n",
       "             'ext': {'brunswick ave ext'},\n",
       "             'king': {'West king'},\n",
       "             'lane': {'country club lane'},\n",
       "             'rd': {'Cricket rd', 'Lawrenceville rd'},\n",
       "             'road': {'Morehall road', 'Newtown-Langhorne road'},\n",
       "             'south': {'Route 130 south'},\n",
       "             'st': {'Main st',\n",
       "              'centre st',\n",
       "              'clay st',\n",
       "              'e front st',\n",
       "              'e state st',\n",
       "              'jackson st',\n",
       "              'livingston st',\n",
       "              'market st',\n",
       "              'mercer st',\n",
       "              'pear st',\n",
       "              's 3rd st',\n",
       "              's broad st',\n",
       "              's montgomery st',\n",
       "              's stockton st',\n",
       "              's warren st',\n",
       "              'st',\n",
       "              'w state st'},\n",
       "             'st.': {'E. State st.'},\n",
       "             'street': {'9th street',\n",
       "              'Broad street',\n",
       "              'East ontario street',\n",
       "              'Westmoreland street',\n",
       "              'south street',\n",
       "              'tilton street'},\n",
       "             'susquahana': {'thompson and susquahana'},\n",
       "             'way': {'mortgage way'}})"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit(osm_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Code for Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<node changeset=\"34353963\" id=\"1483624883\" lat=\"39.9787384\" lon=\"-75.3038692\" timestamp=\"2015-09-30T19:10:51Z\" uid=\"3276050\" user=\"JCarden\" version=\"2\">\\n<tag k=\"name\" v=\"Kettle\"/>\\n<tag k=\"amenity\" v=\"restaurant\"/>\\n<tag k=\"cuisine\" v=\"Diner\"/>\\n<tag k=\"addr:street\" v=\"1 Brookline Boulevard Havertown PA 19083(610) 446-1234\"/><tag k=\"phone\" v=\"(610) 446-1234\"/>\\n<tag k=\"addr:postcode\" v=\"19083\"/>\\n<tag k=\"addr:housenumber\" v=\"1\"/>\\n</node>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_osm_xml = \"\"\"\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<osm>\n",
    " <node changeset=\"34353963\" id=\"1483624883\" lat=\"39.9787384\" lon=\"-75.3038692\" timestamp=\"2015-09-30T19:10:51Z\" uid=\"3276050\" user=\"JCarden\" version=\"2\">\n",
    "  <tag k=\"name\" v=\"Kettle\"/>\n",
    "  <tag k=\"amenity\" v=\"restaurant\"/>\n",
    "  <tag k=\"cuisine\" v=\"Diner\"/>\n",
    "  <tag k=\"addr:street\" v=\"1 Brookline Boulevard Havertown PA 19083(610) 446-1234\"/>\n",
    "  <tag k=\"addr:postcode\" v=\"19083\"/>\n",
    "  <tag k=\"addr:housenumber\" v=\"1\"/>\n",
    " </node>\n",
    "</osm>\n",
    "\"\"\"\n",
    "\n",
    "# Retrieve all tags with the \"addr:street\" attribute\n",
    "test_soup = BeautifulSoup(test_osm_xml, \"xml\")\n",
    "    \n",
    "street_tgs = test_soup.find_all(\"tag\", attrs={\"k\": \"addr:street\"})\n",
    "\n",
    "# Iterate through the list of these tags searching for strings that match regex patterns for other fields, like telephone numbers.\n",
    "# If any strings belong in other fields, add a new tag with the correct attribute. \n",
    "n_tags = []\n",
    "\n",
    "for idx, tag in enumerate(street_tgs):\n",
    "    call_me = phone.search(tag['v'])\n",
    "    if call_me:\n",
    "        v_val = call_me.group()\n",
    "        new_tag = test_soup.new_tag(\"tag\", k=\"phone\", v='{}'.format(v_val))\n",
    "        n_tags.append(new_tag)\n",
    "        tag.insert_after(new_tag)\n",
    "        \n",
    "test_soup\n",
    "# n_tags\n",
    "# type(n_tags[0])\n",
    "\n",
    "# Retrieve the parent node of a given tag\n",
    "for tag in street_tgs:\n",
    "    par = tag.find_parent(\"node\")\n",
    "    ss = par.find_all(\"tag\", attrs={\"k\": \"full\"})\n",
    "\n",
    "# ss\n",
    "par\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', 'Brookline', 'Boulevard', 'Havertown', '19083(610)', '446-1234']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After a value for another field is matched, delete it from the orginal string. \n",
    "n = \"1 Brookline Boulevard Havertown PA 19083(610) 446-1234\"\n",
    "y = pa_state.search(n)\n",
    "xx = n.split()\n",
    "# z = y.group()\n",
    "# type(z)\n",
    "# z\n",
    "for idx, l in enumerate(xx):\n",
    "    keystone = re.search(pa_state, l)\n",
    "    if keystone:\n",
    "        ilt = 'Pennsylvania'\n",
    "        del xx[idx]\n",
    "\n",
    "ilt\n",
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Mullen Road', 70)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./philly_street_full_names_canon.csv', 'r') as streets_canon:\n",
    "    reader = csv.reader(streets_canon)\n",
    "    philly_street_name_canon = list(reader)[0]\n",
    "\n",
    "# Need to exclude matches under 90. Some chance that errors will be introduced for items with common names, like Spruce\n",
    "st_name = process.extractOne('pullen al', philly_street_name_canon)\n",
    "st_name\n",
    "# if st_name[1] > 90:\n",
    "        \n",
    "#   {'206': {'US 70 and US 206'}, ('Campus Crossings E and F street', 86)\n",
    "#              '33': {'Route 33'}, ('South 33rd Street', 68)\n",
    "#              '37th': {'North 37th'}, ('North 37th Street', 90)\n",
    "#              '43rd': {'North 43rd'}, ('North 43rd Street', 90)\n",
    "#              '446-1234': {'1 Brookline Boulevard Havertown PA 19083(610) 446-1234'}, ('Brookline Boulevard', 90)\n",
    "#              '5': {'West Girard Avenue, 5'}, ('West Girard Avenue', 95)\n",
    "#              '70': {'NJ 70', 'US 70'}, ('US 202 Parkway', 86)\n",
    "#              '73': {'New Jersey 73'}, ('New Road', 86)\n",
    "#              '80': {'North Lewis Road Unit #80'}, ('Lewis Road', 90)\n",
    "#              'Bigler': {'Bigler'}, ('Bigler Street', 90)\n",
    "#              'Chestnut': {'Chestnut'}, ('Chestnut Street', 90)\n",
    "#              'Mallon': {'Mallon'}, ('Mallon Street', 90) Mallon Avenue returns ('Marlon Avenue', 92)\n",
    "#              'Moore': {'Cecil B. Moore'}, ('Cecil B Moore Avenue', 95)\n",
    "#              'NJ-73': {'NJ-73'}, ('NJ 73 South / Atlantic City / Old Marlton Pike', 60)\n",
    "#              'PA': {'East Lincoln Highway Langhorne PA'}, ('Lincoln Highway', 90)\n",
    "#              'Spruce': {'Spruce'}, ('Blue Spruce Court', 90)\n",
    "#              'Vine': {'12th and Vine'}, ('Campus Crossings E and F street', 86)\n",
    "#              'Warren': {'Warren'}}) ('Warren Street East', 90)\n",
    "# DAVISVIL LE RO AD, ('Davisville Road', 94)\n",
    "# pullen al, ('Mullen Road', 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_tag_xml = \"\"\"\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<osm>\n",
    " <node changeset=\"34353963\" id=\"1483624883\" lat=\"39.9787384\" lon=\"-75.3038692\" timestamp=\"2015-09-30T19:10:51Z\" uid=\"3276050\" user=\"JCarden\" version=\"2\">\n",
    "  <tag k=\"name\" v=\"Kettle\"/>\n",
    "  <tag k=\"amenity\" v=\"restaurant\"/>\n",
    "  <tag k=\"cuisine\" v=\"Diner\"/>\n",
    "  <tag k=\"addr:street\" v=\"1 Brookline Boulevard Havertown PA 19083(610) 446-1234\"/>\n",
    "  <tag k=\"addr:postcode\" v=\"19083\"/>\n",
    "  <tag k=\"addr:housenumber\" v=\"1\"/>\n",
    "  <tag k=\"addr:street\" v=\"US 70 and US 206\"/>\n",
    "  <tag k=\"addr:street\" v=\"Route 33\"/>\n",
    "  <tag k=\"addr:street\" v=\"West Girard Avenue, 5\"/>\n",
    "  <tag k=\"addr:street\" v=\"North Lewis Road Unit #80\"/>\n",
    "  <tag k=\"addr:street\" v=\"Cecil B. Moore\"/>\n",
    "  <tag k=\"addr:street\" v=\"East Lincoln Highway PA\"/>\n",
    "  <tag k=\"addr:street\" v=\"12th and Vine\"/>\n",
    " </node>\n",
    "</osm>\n",
    "\"\"\"\n",
    "\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "# soup = BeautifulSoup(open(sample_file_k5, \"r+b\"), \"xml\")\n",
    "soup = BeautifulSoup(test_tag_xml, \"xml\")    \n",
    "# street_tags = soup.find_all(\"tag\", attrs={\"k\": \"addr:street\"})\n",
    "# print soup\n",
    "street_tags = soup.find_all(\"tag\", attrs={\"k\" : \"addr:street\"})\n",
    "with open('./philly_street_full_names_canon.csv', 'r') as streets_canon:\n",
    "    reader = csv.reader(streets_canon)\n",
    "    possible_streets = list(reader)[0]\n",
    "\n",
    "    no_fix = ['Mallon Avenue']\n",
    "\n",
    "    for tag in street_tags:\n",
    "        m = street_type_re.search(tag['v'])\n",
    "        street_end = m.group()\n",
    "        intersect = intersection.search(tag['v'])\n",
    "\n",
    "        if street_end not in expected and not intersect and tag['v'] not in no_fix: \n",
    "            st_name = process.extractOne(tag['v'], possible_streets)\n",
    "            print st_name\n",
    "            if st_name[1] >= 90:\n",
    "                tag['v'] = st_name[0]\n",
    "                print tag['v']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main OSM XML Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mapping to replace words may be unnecessary if fuzzy string matching works. \n",
    "# Is there way to reverse this logic, so the values become the keys, and any item matched to a value is replaced with\n",
    "# that value's key? \n",
    "mapping = { \"St\": \"Street\",\n",
    "            \"St.\": \"Street\",\n",
    "           \"st.\": \"Street\",\n",
    "           \"ST\": \"Street\",\n",
    "           \"st\": \"Street\",\n",
    "           \"Sreet\": \"Street\",\n",
    "           \"Sstreet\": \"Street\",\n",
    "            \"Atreet\": \"Street\",\n",
    "           \"Steet\": \"Street\",\n",
    "           \"street\": \"Street\",\n",
    "           \"Sts.\": \"Streets\",\n",
    "           \"AVE\": \"Avenue\",\n",
    "           \"Ave\": \"Avenue\",\n",
    "           \"Ave.\": \"Avenue\",\n",
    "           \"ave\": \"Avenue\",\n",
    "           \"Av\": \"Avenue\",\n",
    "           \"Ave,\": \"Avenue\",\n",
    "           \"avenue\": \"Avenue\",\n",
    "           \"E\": \"East\",\n",
    "           \"E.\": \"East\",\n",
    "           \"e\": \"East\",\n",
    "           \"N\": \"North\",\n",
    "           \"N.\": \"North\",\n",
    "           \"s\": \"South\",\n",
    "           \"S\": \"South\",\n",
    "           \"S.\": \"South\",\n",
    "           \"south\": \"South\",\n",
    "           \"W\": \"West\",\n",
    "           \"Blvd\": \"Boulevard\", \n",
    "           \"Blvd.\": \"Boulevard\",\n",
    "           \"Blv\": \"Boulevard\",\n",
    "           \"Blvd,\": \"Boulevard\",\n",
    "           \"Cir\": \"Circle\",\n",
    "           \"Ct\": \"Court\",\n",
    "           \"Dr\": \"Drive\",\n",
    "           \"Ln\": \"Lane\",\n",
    "           \"ln\": \"Lane\",\n",
    "           \"lane\": \"Lane\",\n",
    "           \"Hwy\":\"Highway\",\n",
    "           \"Hwy,\": \"Highway\",\n",
    "           \"PIke\": \"Pike\",\n",
    "           \"Rd\": \"Road\",\n",
    "           \"Rd.\": \"Road\",\n",
    "           \"rd\": \"Road\",\n",
    "           \"road\": \"Road\",\n",
    "           \"ROAD\": \"Road\",\n",
    "           \"RD\": \"Road\",\n",
    "           \"ext\": \"Extension\",\n",
    "           \"way\": \"Way\",\n",
    "           \"&\": \"and\",\n",
    "           \"Exp\": \"Expressway\",\n",
    "           \"Rmp\": \"Ramp\",\n",
    "           \"Pky\": \"Parkway\",\n",
    "           \"Ter\": \"Terrace\",\n",
    "           \"Tr\": \"Trail\",\n",
    "           \"Sq\": \"Square\",\n",
    "           \"Pkwy\": \"Parkway\",\n",
    "           \"pky\": \"Parkway\",\n",
    "           \"Pl\": \"Place\",\n",
    "           \"Ext\": \"Exit\",\n",
    "           \"Wlk\": \"Walk\",\n",
    "           \"wlk\": \"Walk\",\n",
    "           \"Brg\": \"Bridge\",\n",
    "           \"Tun\": \"Tunnel\",\n",
    "           \"Tnl\": \"Tunnel\",\n",
    "           \"Cre\": \"Crescent\",\n",
    "           \"al\": \"Alley\",\n",
    "           \"Ste\": \"Suite\"\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# filter out zipcodes, phone numbers, and full addresses and add a tag to the parent node with that attribute if it is\n",
    "# not already included in the parent node. \n",
    "\n",
    "# RE similar to below should be able to detect state and national highways. \n",
    "\n",
    "# Between 1 and 4 digits at the beginning or a line, exclude numbered street names like 34th, 23rd, 1st, 42nd\n",
    "house_number = re.compile(r'^(\\d{2,4}|\\b\\d{1}\\b)(?!th|rd|st|nd)', re.IGNORECASE)\n",
    "\n",
    "# |(?<!route )(?<!us )(?<!nj )(?<!jersey )(\\d{2,4}|\\b\\d{1}\\b)(?!th|rd|st|nd)$\n",
    "\n",
    "# unit_number needs to match two digits at the end of a line, unless they follow a state name Or US or have a number ending\n",
    "unit_num = re.compile(r'u.*it ?#?(\\d{2,4} ?|\\b\\d{1}\\b)(?!th|rd|st|nd)$', re.IGNORECASE)\n",
    "\n",
    "# Also suite, ste, ste. Little more complicated, as suite has letters in common with \"Street\"\n",
    "suite_num = re.compile(r'(?<!u)s[u|t]?[i|t]?t?e?.? ?#?(?<!rsey )(?<!ania )(\\d{2,4} ?|\\b\\d{1}\\b)(?!th|rd|st|nd)$', re.IGNORECASE)\n",
    "\n",
    " # Five consecutive digits is very likely a zipcode in this context, though could also restrict to a list of known\n",
    "# zipcodes in the Phillly metro area. \n",
    "zipcode = re.compile(r'\\d{5}')\n",
    "# zip_garbage = re.compile(r'\\d{5}.{3,5}')\n",
    "\n",
    "# any chr, 3 digits, any chr, 3 digits, any chr, 4 digits. As bonus, this will ensure that phone numbers in the DB are\n",
    "# unique\n",
    "phone = re.compile(r'\\(?\\d{3}\\)?[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}') \n",
    "\n",
    "# There should technically be only one city, Philadelphia, though there a few other suburban cities close to Philly included\n",
    "cities = ['Philadelphia', 'Langhorne', 'Morrisville', 'Havertown', 'Levittown', 'Springfield']\n",
    "\n",
    "#Try to abbreviate 'Pennsylvania' or 'New Jersey', I dare you! \n",
    "pa_state = re.compile(r'\\bpen.*\\.?ia\\b|\\bpa\\.?\\b', re.IGNORECASE)\n",
    "\n",
    "#Calibrated to accept regional vernacular varients such as 'Joizy' or 'Joisey'\n",
    "nj_state = re.compile(r'\\bnj\\b|new ?j.*y|j.*y', re.IGNORECASE)\n",
    "\n",
    "# If words aren't spaced, like 'BrooklineBlvd'\n",
    "abutted = re.compile(r'([A-Z]{1}\\w+)([A-Z]\\w+)')\n",
    "\n",
    "# ALL CAPS\n",
    "all_cap = re.compile(r'[A-Z]{3,}') # At least 3 caps \n",
    "\n",
    "#fix all lower to normal case\n",
    "all_low = re.compile(r'\\b[a-z]{4,}\\b') # At least 4 lower case chrs with whitespace before and after\n",
    "\n",
    "# If two words joined by 'and' or '&', add \"Streets\" Doesn't yet match '&amp'\n",
    "intersection = re.compile(r'(\\w+\\s\\band\\b\\s\\w+)|(\\w+\\s\\b&\\b\\s\\w+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from __future__ import division\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# Iterate through the list of words in each street name, check to see if any match a state name, house number, \n",
    "# phone number, or zipcode. If one of the words matches, insert it into the tree as a new tag.\n",
    "# If the OSM file addr:street contains information for other fields, extract this information and create a new tag.\n",
    "\n",
    "def clean_streets(osmfile):\n",
    "    start_time = time.time()\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "    \n",
    "    soup = BeautifulSoup(open(osmfile, \"r+b\"), \"xml\")\n",
    "    \n",
    "    street_tags = soup.find_all(\"tag\", attrs={\"k\": \"addr:street\"})\n",
    "    phones = soup.find_all(\"tag\", attrs={\"k\": \"phone\"})\n",
    "\n",
    "    for tag in street_tags:\n",
    "        par = tag.find_parent(\"node\")\n",
    "        \n",
    "        # Check if string contains a housenumber and insert new tag if so\n",
    "        num = house_number.search(tag['v'])\n",
    "        if num and par != None:\n",
    "            snum = par.find_all(\"tag\", attrs={\"k\": \"addr:housenumber\"})\n",
    "            v_val = num.group()\n",
    "            new_tag = soup.new_tag(\"tag\", k=\"addr:housenumber\", v='{}'.format(v_val))\n",
    "            if new_tag not in snum:\n",
    "                tag.insert_after(new_tag)\n",
    "                re.sub(house_number,'', tag['v']) # None of these substitutions are working\n",
    "        \n",
    "        #Check if string contains phone number and insert new tag if so\n",
    "        call_me = phone.search(tag['v'])\n",
    "        if call_me:\n",
    "            v_val = call_me.group()\n",
    "            new_tag = soup.new_tag(\"tag\", k=\"phone\", v='{}'.format(v_val))\n",
    "            if new_tag not in phones:\n",
    "                tag.insert_after(new_tag)\n",
    "                re.sub(phone,'',tag['v'])\n",
    "        \n",
    "        post = zipcode.search(tag['v'])\n",
    "        if post and par != None:\n",
    "            ezips = par.find_all(\"tag\", attrs={\"k\": \"addr:postcode\"})\n",
    "            v_val = post.group()\n",
    "            new_tag = soup.new_tag(\"tag\", k=\"addr:postcode\", v='{}'.format(v_val))\n",
    "            if new_tag not in ezips:    \n",
    "                tag.insert_after(new_tag)        \n",
    "                re.sub(zipcode,'', tag['v'])\n",
    "                \n",
    "        sweet = suite_num.search(tag['v'])\n",
    "        if sweet and par != None: \n",
    "            sweets = par.find_all(\"tag\", attrs={\"k\": \"addr:suite\"})\n",
    "            v_val = sweet.group()\n",
    "            new_tag = soup.new_tag(\"tag\", k=\"addr:suite\", v='{}'.format(v_val))\n",
    "            if new_tag not in sweets:\n",
    "                tag.insert_after(new_tag)\n",
    "                re.sub(suite_num,'', tag['v'])\n",
    "        \n",
    "        uno = unit_num.search(tag['v'])\n",
    "        if uno and par != None: \n",
    "            units = par.find_all(\"tag\", attrs={\"k\": \"addr:unit\"})\n",
    "            v_val = uno.group()\n",
    "            new_tag = soup.new_tag(\"tag\", k=\"addr:unit\", v='{}'.format(v_val))\n",
    "            if new_tag not in units:\n",
    "                tag.insert_after(new_tag)\n",
    "                re.sub(unit_num,'', tag['v'])\n",
    "\n",
    "        keystone = pa_state.search(tag['v'])\n",
    "        if keystone:\n",
    "            new_tag = soup.new_tag(\"tag\", k=\"addr:state\", v=\"Pennsylvania\")\n",
    "            tag.insert_after(new_tag)\n",
    "            re.sub(pa_state,'', tag['v'])\n",
    "            \n",
    "        joizy = nj_state.search(tag['v'])        \n",
    "        if joizy:\n",
    "            new_tag = soup.new_tag(\"tag\", k=\"addr:city\", v=\"New Jesery\")\n",
    "            tag.insert_after(new_tag)\n",
    "            re.sub(nj_state,'', tag['v'])\n",
    "    \n",
    "    osmfile_write = './full_osm_clean.osm'\n",
    "    \n",
    "    with open(osmfile_write, \"w\") as f:\n",
    "        f.write(soup.prettify())\n",
    "    print(\"--- {}min ---\".format((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 26-28 min runtime\n",
    "clean_full_osm = './full_osm_clean.osm'\n",
    "clean_streets(osm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'1': {'Route 1'},\n",
       "             '111': {'South Clinton Avenue Ste. 111'},\n",
       "             '13': {'W Main St #13'},\n",
       "             '168': {'Marlton Pike East Ste. 168'},\n",
       "             '19047': {'200 Manor Ave. Langhorne, PA 19047',\n",
       "              '2245 E. Lincoln Hwy, Langhorne, PA 19047',\n",
       "              '2275 E Lincoln Hwy, Langhorne, PA 19047',\n",
       "              '2300  East Lincoln Highway, Pennsylvania 19047'},\n",
       "             '19067': {'East Trenton Avenue Morrisville, PA 19067'},\n",
       "             '206': {'US 206', 'US 70 & US 206'},\n",
       "             '33': {'Route 33'},\n",
       "             '37th': {'N 37th'},\n",
       "             '38': {'New Jersey 38', 'New Jersey Route 38', 'Route 38'},\n",
       "             '39th': {'N 39th'},\n",
       "             '40': {'1140 US Highway 40', 'Rt 40'},\n",
       "             '4080': {'4080'},\n",
       "             '41st': {'S. 41st'},\n",
       "             '43rd': {'N 43rd'},\n",
       "             '446-1234': {'1 Brookline BlvdHavertown, PA 19083(610) 446-1234'},\n",
       "             '452': {'Market Street; Pennsylvania Route 452',\n",
       "              'Pennel Road; Pennsylvania Route 452'},\n",
       "             '5': {'West Girard Avenue, 5'},\n",
       "             '53rd': {'N 53rd'},\n",
       "             '611': {'Easton Road Route 611'},\n",
       "             '70': {'NJ 70', 'US 70'},\n",
       "             '73': {'NJ 73', 'New Jersey 73', 'North Route 73', 'Route 73'},\n",
       "             '80': {'N Lewis RD Unit #80'},\n",
       "             '902': {'Chestnut Street #902'},\n",
       "             'AVE': {'EDGMONT AVE'},\n",
       "             'Atreet': {'Arch Atreet'},\n",
       "             'Ave': {'517 W Girard Ave',\n",
       "              '72nd Ave and Orgontz Ave',\n",
       "              '8401 Frankford Ave',\n",
       "              'Alden Ave',\n",
       "              'Aramingo Ave',\n",
       "              'Baltimore Ave',\n",
       "              'Bishop Ave, Clifton Ave',\n",
       "              'Bryn Mawr Ave',\n",
       "              'Chester Ave',\n",
       "              'Constitution Ave',\n",
       "              'Cottman Ave',\n",
       "              'Devon St & Mt. Pleasant Ave',\n",
       "              'E Butler Ave',\n",
       "              'E Lancaster Ave',\n",
       "              'E. Mt Airy Ave',\n",
       "              'East Lancaster Ave',\n",
       "              'East Wadsworth Ave',\n",
       "              'Essington Ave',\n",
       "              'Fairmount Ave',\n",
       "              'Fort Washington Ave',\n",
       "              'Frankford Ave',\n",
       "              'Germantown Ave',\n",
       "              'Grant Ave',\n",
       "              'Grays Ave',\n",
       "              'Hirst Ave',\n",
       "              'Lancaster Ave',\n",
       "              'Montgomery Ave',\n",
       "              'Mt.Ephraim Ave',\n",
       "              'N Olden Ave',\n",
       "              'Park Ave',\n",
       "              'Parkway Ave',\n",
       "              'Pennington Ave',\n",
       "              'Pennsylvania Ave',\n",
       "              'Penrose Ave',\n",
       "              'Philmont Ave',\n",
       "              'Rising Sun Ave',\n",
       "              'S Clinton Ave',\n",
       "              'S Washington Ave',\n",
       "              'S. Clinton Ave',\n",
       "              'Sharon Ave',\n",
       "              'Sloan Ave',\n",
       "              'Stenton Ave',\n",
       "              'Summit Ave',\n",
       "              'Washington Ave',\n",
       "              'West Butler Ave',\n",
       "              'West Girard Ave',\n",
       "              'West Glenside Ave',\n",
       "              'West Huntington Ave',\n",
       "              'West Mermaid Lane and Germantown Ave',\n",
       "              'West Montgomery Ave',\n",
       "              'West Trenton Ave'},\n",
       "             'Ave.': {'Aramingo Ave.',\n",
       "              'Baltimore Ave.',\n",
       "              'Bonny Brook Ave.',\n",
       "              'East Butler Ave.',\n",
       "              'Germantown Ave.',\n",
       "              'Morton Ave.',\n",
       "              'Station Ave.',\n",
       "              'Taylor Ave.',\n",
       "              'West Butler Ave.'},\n",
       "             'Bigler': {'Bigler'},\n",
       "             'Blvd': {'Brookline Blvd',\n",
       "              'Centennial Blvd',\n",
       "              'Floral Vale Blvd',\n",
       "              'Garden Gold Blvd',\n",
       "              'Garden Golf Blvd',\n",
       "              'Hearthstone Blvd',\n",
       "              'Nassau Park Blvd',\n",
       "              'Nassau Parl Blvd',\n",
       "              'S Christopher Columbus Blvd',\n",
       "              'Shannondell Blvd'},\n",
       "             'Blvd.': {'Brookline Blvd.'},\n",
       "             'Brown': {'N 37th & Brown'},\n",
       "             'Center': {'Town Center'},\n",
       "             'Chestnut': {'Chestnut'},\n",
       "             'Chippendale': {'Chippendale'},\n",
       "             'Cir': {'Woodfield Cir'},\n",
       "             'Cricket': {'Cricket'},\n",
       "             'Ct': {'Portsmouth Ct'},\n",
       "             'D102': {'Henry Ave #D102'},\n",
       "             'Dr': {'Deerpath Dr',\n",
       "              'Merrill Lynch Dr',\n",
       "              'Revere Dr',\n",
       "              \"Tommy's Meadow Dr\"},\n",
       "             'E': {'NJ-70 E'},\n",
       "             'Front': {'S Front'},\n",
       "             'Garden': {'Spring Garden'},\n",
       "             'Greene': {'Greene'},\n",
       "             'Haverford': {'Haverford'},\n",
       "             'Hook': {'Calcon Hook'},\n",
       "             'Hutchinson': {'North Hutchinson'},\n",
       "             'Hwy': {'Harding Hwy'},\n",
       "             'Ln': {'Hartford Ln', 'Patricia Ln', 'Simpkins Ln'},\n",
       "             'Mallon': {'Mallon'},\n",
       "             'Maple': {'South Maple'},\n",
       "             'Market': {'Market'},\n",
       "             'Master': {'15th and Master'},\n",
       "             'Moore': {'Cecil B. Moore'},\n",
       "             'NJ-73': {'NJ-73'},\n",
       "             'Nixon': {'Shawmont & Nixon'},\n",
       "             'PA': {'Baltimore Pike, Springfield, PA',\n",
       "              'E Lincoln HwyLanghorne, PA',\n",
       "              'E. Lincoln Highway Langhore, PA',\n",
       "              'Saxer Ave, Springfield, PA'},\n",
       "             'PA.': {'Trenton Rd - Levittown, PA.'},\n",
       "             'PIke': {'Princeton PIke'},\n",
       "             'Parrish': {'Parrish'},\n",
       "             'Preston': {'N Preston'},\n",
       "             'ROAD': {'DAVISVILLE ROAD', 'TERWOOD ROAD', 'TOWNSHIP LINE ROAD'},\n",
       "             'Rd': {'22 Centerton Rd',\n",
       "              '24 Centerton Rd',\n",
       "              '40 Centerton Rd',\n",
       "              '50 Centerton Rd',\n",
       "              '52 Centerton Rd',\n",
       "              '58 Centerton Rd',\n",
       "              '62 Centerton Rd',\n",
       "              '66 Centerton Rd',\n",
       "              '70 Centerton Rd',\n",
       "              'Abrams Mill Rd',\n",
       "              'Anderson Rd',\n",
       "              \"Arney's Mount Rd\",\n",
       "              'Barren Hill Rd',\n",
       "              'Bristol Rd',\n",
       "              'Calcon Hook Rd',\n",
       "              'Church Rd',\n",
       "              'Clements Bridge Rd',\n",
       "              'Cross Keys Rd',\n",
       "              'Darby Rd',\n",
       "              'Deptford Center Rd',\n",
       "              'Dilworthtown Rd',\n",
       "              'Durham Rd',\n",
       "              'Easton Rd',\n",
       "              'Edison Furlong Rd',\n",
       "              'Evesham Rd',\n",
       "              'Grove Rd',\n",
       "              'Haddonfield Rd',\n",
       "              'Hulmeville Rd',\n",
       "              'Hurffville  Rd',\n",
       "              'Hurffville Rd',\n",
       "              'Kimberton Rd',\n",
       "              'King Rd',\n",
       "              'Lincoln Mill Rd',\n",
       "              'Meetinghouse Rd',\n",
       "              'N Providence Rd',\n",
       "              'Old Cuthbert Rd',\n",
       "              'S Easton Rd',\n",
       "              'Schuylkill Rd',\n",
       "              'South Easton Rd',\n",
       "              'Stokes Rd',\n",
       "              'Valley Rd',\n",
       "              'W Cohawkin Rd',\n",
       "              'York Rd'},\n",
       "             'Rd.': {'Clements Bridge Rd.',\n",
       "              'Kagey Rd.',\n",
       "              'N. Lewis Rd.',\n",
       "              'North Lewis Rd.',\n",
       "              'S. Chester Rd.',\n",
       "              'W. Street Rd.',\n",
       "              'Wistar Rd.',\n",
       "              'York Rd.'},\n",
       "             'Reno': {'North 50th Street & Reno'},\n",
       "             'S': {'Route 73 S'},\n",
       "             'ST': {'S 6TH ST'},\n",
       "             'Salina': {'Salina'},\n",
       "             'Sheffield': {'Sheffield'},\n",
       "             'Sloan': {'Sloan'},\n",
       "             'Spruce': {'Spruce'},\n",
       "             'Sreet': {'Bridge Sreet'},\n",
       "             'Sstreet': {'South 9th Sstreet'},\n",
       "             'St': {'46th and Market St',\n",
       "              '507 E Tulpehocken St',\n",
       "              'Baring St',\n",
       "              'Bush St',\n",
       "              'Carson St',\n",
       "              'Center St',\n",
       "              'Chestnut St',\n",
       "              'Coates St',\n",
       "              'Cooper St',\n",
       "              'Dickinson St',\n",
       "              'E Front St',\n",
       "              'E Hampton St',\n",
       "              'E Hector St',\n",
       "              'E Luzerne St',\n",
       "              'E Penn St',\n",
       "              'E State St',\n",
       "              'E Wingohocking St',\n",
       "              'E. Passyunk Ave and Kauffman St',\n",
       "              'Federal St',\n",
       "              'Front St & Tasker St',\n",
       "              'Green St',\n",
       "              'Johnston St',\n",
       "              'Market St',\n",
       "              'McKean St',\n",
       "              'N 4th St',\n",
       "              'N 5th St',\n",
       "              'N 6th St',\n",
       "              'N Broad St',\n",
       "              'N Gratz St',\n",
       "              'N Main St',\n",
       "              'North Broad St',\n",
       "              'North Front St',\n",
       "              'Quarry St',\n",
       "              'Race St',\n",
       "              'Ranstead St',\n",
       "              'Rhawn St',\n",
       "              'S 19th St',\n",
       "              'S 20th St',\n",
       "              'S 22nd St',\n",
       "              'S 24th St',\n",
       "              'S 28th St',\n",
       "              'S 3rd St',\n",
       "              'S 41st St',\n",
       "              'S 47th St',\n",
       "              'S 4th St',\n",
       "              'S 50th St',\n",
       "              'S Broad St',\n",
       "              'S Main St',\n",
       "              'S Norwood St',\n",
       "              'S Warren St',\n",
       "              'South 40th St',\n",
       "              'South Bancroft St',\n",
       "              'South St',\n",
       "              'South St Bernard St',\n",
       "              'Spring Garden St',\n",
       "              'St John St',\n",
       "              'Starr St',\n",
       "              'W State St',\n",
       "              'Walnut St',\n",
       "              'Washington St',\n",
       "              'West Main St'},\n",
       "             'St.': {'12th St.',\n",
       "              'Almond St.',\n",
       "              'Diamond St.',\n",
       "              'E. State St.',\n",
       "              'Mt. Pleasant Ave, Devon St, Sprague St.',\n",
       "              'N 24th St.',\n",
       "              'S. 15th St.',\n",
       "              'S. 40th St.',\n",
       "              'South Broad St.',\n",
       "              'W. State St.'},\n",
       "             'Steet': {'South 18th Steet'},\n",
       "             'Stiles': {'16th and Stiles'},\n",
       "             'StreetPhiladelphia': {'117 South 18th StreetPhiladelphia'},\n",
       "             'Sts.': {'1st and Seneca Sts.'},\n",
       "             'Sycamore': {'North Sycamore'},\n",
       "             'Thompson': {'Sletcher and Thompson'},\n",
       "             'Vine': {'12th and Vine'},\n",
       "             'W': {'NJ 70 W'},\n",
       "             'W5': {'Presidential Blvd, Ste W5'},\n",
       "             'Warminster': {'Warminster'},\n",
       "             'Warren': {'Warren'},\n",
       "             'al': {'pullen al'},\n",
       "             'ave': {'and 1891 brunswick ave',\n",
       "              'hillcrest ave',\n",
       "              'michigan ave'},\n",
       "             'avenue': {'Ohio avenue'},\n",
       "             'ext': {'brunswick ave ext'},\n",
       "             'king': {'West king'},\n",
       "             'lane': {'country club lane'},\n",
       "             'rd': {'Cricket rd', 'Lawrenceville rd'},\n",
       "             'road': {'Morehall road', 'Newtown-Langhorne road'},\n",
       "             'south': {'Route 130 south'},\n",
       "             'st': {'Main st',\n",
       "              'centre st',\n",
       "              'clay st',\n",
       "              'e front st',\n",
       "              'e state st',\n",
       "              'jackson st',\n",
       "              'livingston st',\n",
       "              'market st',\n",
       "              'mercer st',\n",
       "              'pear st',\n",
       "              's 3rd st',\n",
       "              's broad st',\n",
       "              's montgomery st',\n",
       "              's stockton st',\n",
       "              's warren st',\n",
       "              'st',\n",
       "              'w state st'},\n",
       "             'st.': {'E. State st.'},\n",
       "             'street': {'9th street',\n",
       "              'Broad street',\n",
       "              'East ontario street',\n",
       "              'Westmoreland street',\n",
       "              'south street',\n",
       "              'tilton street'},\n",
       "             'susquahana': {'thompson and susquahana'},\n",
       "             'way': {'mortgage way'}})"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit(clean_full_osm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.5 min runtime on 1/5 file, likely over 17 min for full file. 2nd version taking nearly 6 min for 1/5 file\n",
    "clean_streets(sample_file_k5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'206': {'US 70 & US 206'},\n",
       "             '33': {'Route 33'},\n",
       "             '37th': {'N 37th'},\n",
       "             '43rd': {'N 43rd'},\n",
       "             '446-1234': {'1 Brookline BlvdHavertown, PA 19083(610) 446-1234'},\n",
       "             '5': {'West Girard Avenue, 5'},\n",
       "             '70': {'NJ 70', 'US 70'},\n",
       "             '73': {'New Jersey 73'},\n",
       "             '80': {'N Lewis RD Unit #80'},\n",
       "             'Ave': {'Aramingo Ave',\n",
       "              'Cottman Ave',\n",
       "              'Devon St & Mt. Pleasant Ave',\n",
       "              'E. Mt Airy Ave',\n",
       "              'Fairmount Ave',\n",
       "              'Fort Washington Ave',\n",
       "              'Frankford Ave',\n",
       "              'Germantown Ave',\n",
       "              'Grays Ave',\n",
       "              'Hirst Ave',\n",
       "              'Montgomery Ave',\n",
       "              'Park Ave',\n",
       "              'Parkway Ave',\n",
       "              'S Clinton Ave',\n",
       "              'Stenton Ave',\n",
       "              'West Girard Ave'},\n",
       "             'Ave.': {'Bonny Brook Ave.',\n",
       "              'East Butler Ave.',\n",
       "              'West Butler Ave.'},\n",
       "             'Bigler': {'Bigler'},\n",
       "             'Blvd': {'Centennial Blvd',\n",
       "              'Garden Golf Blvd',\n",
       "              'Hearthstone Blvd',\n",
       "              'Nassau Parl Blvd'},\n",
       "             'Center': {'Town Center'},\n",
       "             'Chestnut': {'Chestnut'},\n",
       "             'Cir': {'Woodfield Cir'},\n",
       "             'Dr': {\"Tommy's Meadow Dr\"},\n",
       "             'Ln': {'Hartford Ln', 'Simpkins Ln'},\n",
       "             'Mallon': {'Mallon'},\n",
       "             'Moore': {'Cecil B. Moore'},\n",
       "             'NJ-73': {'NJ-73'},\n",
       "             'PA': {'E Lincoln HwyLanghorne, PA'},\n",
       "             'PIke': {'Princeton PIke'},\n",
       "             'Rd': {\"Arney's Mount Rd\",\n",
       "              'Bristol Rd',\n",
       "              'Calcon Hook Rd',\n",
       "              'Clements Bridge Rd',\n",
       "              'Dilworthtown Rd',\n",
       "              'Edison Furlong Rd',\n",
       "              'Grove Rd',\n",
       "              'Hulmeville Rd',\n",
       "              'Hurffville  Rd',\n",
       "              'Hurffville Rd',\n",
       "              'Meetinghouse Rd',\n",
       "              'Old Cuthbert Rd',\n",
       "              'South Easton Rd',\n",
       "              'W Cohawkin Rd',\n",
       "              'York Rd'},\n",
       "             'Rd.': {'Kagey Rd.', 'N. Lewis Rd.'},\n",
       "             'ST': {'S 6TH ST'},\n",
       "             'Spruce': {'Spruce'},\n",
       "             'St': {'Carson St',\n",
       "              'Center St',\n",
       "              'Dickinson St',\n",
       "              'E Hampton St',\n",
       "              'E Luzerne St',\n",
       "              'E State St',\n",
       "              'Green St',\n",
       "              'Market St',\n",
       "              'N 4th St',\n",
       "              'N 5th St',\n",
       "              'N Broad St',\n",
       "              'N Main St',\n",
       "              'North Front St',\n",
       "              'S 20th St',\n",
       "              'S 22nd St',\n",
       "              'S 24th St',\n",
       "              'S 41st St',\n",
       "              'S Broad St',\n",
       "              'Spring Garden St'},\n",
       "             'St.': {'Diamond St.',\n",
       "              'E. State St.',\n",
       "              'N 24th St.',\n",
       "              'S. 15th St.',\n",
       "              'South Broad St.'},\n",
       "             'Vine': {'12th and Vine'},\n",
       "             'Warren': {'Warren'},\n",
       "             'ave': {'michigan ave'},\n",
       "             'avenue': {'Ohio avenue'},\n",
       "             'rd': {'Lawrenceville rd'},\n",
       "             'south': {'Route 130 south'},\n",
       "             'st': {'centre st',\n",
       "              'clay st',\n",
       "              'e front st',\n",
       "              'e state st',\n",
       "              'jackson st',\n",
       "              'market st',\n",
       "              'mercer st',\n",
       "              'pear st',\n",
       "              's 3rd st',\n",
       "              's broad st',\n",
       "              's montgomery st',\n",
       "              's warren st',\n",
       "              'w state st'},\n",
       "             'street': {'tilton street'}})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit(sample_file_k5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean up words in the addr:street attributes \n",
    "def filter_words(osmfile):\n",
    "    start_time = time.time()\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "    soup = BeautifulSoup(open(osmfile, \"r+b\"), \"xml\")\n",
    "    \n",
    "    street_tags = soup.find_all(\"tag\", attrs={\"k\": \"addr:street\"})    \n",
    "\n",
    "    for tag in street_tags:\n",
    "        words = tag['v'].split()\n",
    "            \n",
    "        street_orphans = ['Spruce', 'Bigler', 'Warren', 'Chippendale', 'Front', 'Greene', 'Market', 'Sloan', 'Salina'\n",
    "                         'Warren', 'Chestnut', 'North 37th']\n",
    "        \n",
    "        if tag['v'] in street_orphans:\n",
    "            words.append('Street')\n",
    "            \n",
    "        av_orphans = ['Mallon']\n",
    "        \n",
    "        if tag['v'] in av_orphans:\n",
    "            words.append('Avenue')\n",
    "                \n",
    "        for idx, word in enumerate(words):\n",
    "            \n",
    "            if word in cities:\n",
    "                new_tag = soup.new_tag(\"tag\", k=\"addr:city\", v='{}'.format(word))\n",
    "                tag.insert_after(new_tag)\n",
    "                del words[idx]\n",
    "    \n",
    "            no_space = re.search(abutted, word)\n",
    "            if no_space:\n",
    "                words[idx] = abutted.sub(r'\\1', word).strip(',')\n",
    "                words.insert(idx+1, re.sub(abutted, r'\\2', word).strip(','))\n",
    "            caps = all_cap.search(word) #caps nor lowered don't seem to be working\n",
    "            if caps:\n",
    "                words[idx] = word[idx].title()\n",
    "            lowered = all_low.search(word)\n",
    "            if lowered:\n",
    "                words[idx] = words[idx].capitalize()\n",
    "        \n",
    "        clean_name = ' '.join(str(mapping.get(word, word)) for word in words).strip(',')\n",
    "        tag['v'] = str(clean_name)\n",
    "    \n",
    "    with open(osmfile, \"w\") as f:\n",
    "        f.write(soup.prettify())\n",
    "    print(\"--- {}min ---\".format((time.time() - start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 20 min for full file\n",
    "filter_words(clean_full_osm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'1': {'Route 1'},\n",
       "             '111': {'South Clinton Avenue Ste. 111'},\n",
       "             '13': {'West Main Street #13'},\n",
       "             '168': {'Marlton Pike East Ste. 168'},\n",
       "             '19047': {'200 Manor Avenue Langhorne, PA 19047',\n",
       "              '2245 East Lincoln Highway Langhorne, PA 19047',\n",
       "              '2275 East Lincoln Highway Langhorne, PA 19047',\n",
       "              '2300 East Lincoln Highway, Pennsylvania 19047'},\n",
       "             '19067': {'East Trenton Avenue Morrisville, PA 19067'},\n",
       "             '206': {'US 206', 'US 70 and US 206'},\n",
       "             '33': {'Route 33'},\n",
       "             '37th': {'North 37th'},\n",
       "             '38': {'New Jersey 38', 'New Jersey Route 38', 'Route 38'},\n",
       "             '39th': {'North 39th'},\n",
       "             '40': {'1140 US Highway 40'},\n",
       "             '4080': {'4080'},\n",
       "             '41st': {'South 41st'},\n",
       "             '43rd': {'North 43rd'},\n",
       "             '446-1234': {'1 Brookline Boulevard PA 19083(610) 446-1234'},\n",
       "             '452': {'Market Street; Pennsylvania Route 452',\n",
       "              'Pennel Road; Pennsylvania Route 452'},\n",
       "             '5': {'West Girard Avenue, 5'},\n",
       "             '53rd': {'North 53rd'},\n",
       "             '611': {'Easton Road Route 611'},\n",
       "             '70': {'NJ 70', 'US 70'},\n",
       "             '73': {'NJ 73', 'New Jersey 73', 'North Route 73', 'Route 73'},\n",
       "             '80': {'North Lewis Road Unit #80'},\n",
       "             '902': {'Chestnut Street #902'},\n",
       "             'AD': {'DAVISVIL LE RO AD',\n",
       "              'TERWO OD RO AD',\n",
       "              'TOWNSH IP LI NE RO AD'},\n",
       "             'Brown': {'North 37th and Brown'},\n",
       "             'Center': {'Town Center'},\n",
       "             'Cricket': {'Cricket'},\n",
       "             'D102': {'Henry Avenue #D102'},\n",
       "             'Front': {'South Front'},\n",
       "             'Garden': {'Spring Garden'},\n",
       "             'Haverford': {'Haverford'},\n",
       "             'Hook': {'Calcon Hook'},\n",
       "             'Hutchinson': {'North Hutchinson'},\n",
       "             'Maple': {'South Maple'},\n",
       "             'Master': {'15th and Master'},\n",
       "             'Moore': {'Cecil B. Moore'},\n",
       "             'NJ-73': {'NJ-73'},\n",
       "             'Nixon': {'Shawmont and Nixon'},\n",
       "             'PA': {'Baltimore Pike, Springfield, PA',\n",
       "              'East Lincoln Highway Langhore, PA',\n",
       "              'East Lincoln Highway PA',\n",
       "              'Saxer Avenue Springfield, PA'},\n",
       "             'PA.': {'Trenton Road - Levittown, PA.'},\n",
       "             'Parrish': {'Parrish'},\n",
       "             'Preston': {'North Preston'},\n",
       "             'Reno': {'North 50th Street and Reno'},\n",
       "             'Salina': {'Salina'},\n",
       "             'Sheffield': {'Sheffield'},\n",
       "             'Stiles': {'16th and Stiles'},\n",
       "             'Sycamore': {'North Sycamore'},\n",
       "             'Thompson': {'Sletcher and Thompson'},\n",
       "             'Vine': {'12th and Vine'},\n",
       "             'W5': {'Presidential Boulevard Suite W5'},\n",
       "             'Warminster': {'Warminster'},\n",
       "             'king': {'West king'},\n",
       "             'susquahana': {'thompson and susquahana'}})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit(clean_full_osm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2.57 min 1/5 data, full data likely over 12 min. 2nd version took about 11 min for 1/5 data. \n",
    "filter_words(sample_file_k5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'206': {'US 70 and US 206'},\n",
       "             '33': {'Route 33'},\n",
       "             '37th': {'North 37th'},\n",
       "             '446-1234': {'1 Brookline Boulevard PA 19083(610) 446-1234'},\n",
       "             '5': {'West Girard Avenue, 5'},\n",
       "             '70': {'NJ 70', 'US 70'},\n",
       "             '73': {'New Jersey 73'},\n",
       "             '80': {'North Lewis Road Unit #80'},\n",
       "             'Moore': {'Cecil B. Moore'},\n",
       "             'NJ-73': {'NJ-73'},\n",
       "             'PA': {'East Lincoln Highway PA'},\n",
       "             'Vine': {'12th and Vine'}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audit(sample_file_k5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximate (Fuzzy) String Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n",
    "import time, sys\n",
    "\n",
    "def fix_street_names(osmfile):\n",
    "    start_time = time.time()\n",
    "    reload(sys)\n",
    "    sys.setdefaultencoding('utf-8')\n",
    "    soup = BeautifulSoup(open(osmfile, \"r+b\"), \"xml\")\n",
    "    \n",
    "    street_tags = soup.find_all(\"tag\", attrs={\"k\": \"addr:street\"})\n",
    "    \n",
    "    with open('./philly_street_full_names_canon.csv', 'r') as streets_canon:\n",
    "        reader = csv.reader(streets_canon)\n",
    "        possible_streets = list(reader)[0]\n",
    "    \n",
    "    no_fix = ['Mallon Avenue']\n",
    "    \n",
    "    # Only run for those records yielded from the audit function\n",
    "    for tag in street_tags:\n",
    "        m = street_type_re.search(tag['v'])\n",
    "        street_end = m.group()\n",
    "        intersect = intersection.search(tag['v'])\n",
    "\n",
    "        if street_end not in expected and not intersect and tag['v'] not in no_fix: \n",
    "            st_name = process.extractOne(tag['v'], possible_streets)\n",
    "            if st_name[1] >= 90:\n",
    "                tag['v'] = st_name[0]\n",
    "\n",
    "    with open(osmfile, \"w\") as f:\n",
    "        f.write(soup.prettify())\n",
    "    print(\"--- {}min ---\".format((time.time() - start_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 25-28 min runtime\n",
    "fix_street_names(clean_full_osm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'1': {'Route 1'},\n",
       "             '206': {'US 206', 'US 70 and US 206'},\n",
       "             '33': {'Route 33'},\n",
       "             '38': {'New Jersey 38', 'New Jersey Route 38', 'Route 38'},\n",
       "             '40': {'1140 US Highway 40', 'Rt 40'},\n",
       "             '4080': {'4080'},\n",
       "             '70': {'NJ 70', 'US 70'},\n",
       "             '73': {'NJ 73', 'New Jersey 73', 'North Route 73', 'Route 73'},\n",
       "             'Brown': {'North 37th and Brown'},\n",
       "             'Master': {'15th and Master'},\n",
       "             'NJ-73': {'NJ-73'},\n",
       "             'Nixon': {'Shawmont and Nixon'},\n",
       "             'Reno': {'North 50th Street and Reno'},\n",
       "             'Stiles': {'16th and Stiles'},\n",
       "             'Thompson': {'Sletcher and Thompson'},\n",
       "             'Vine': {'12th and Vine'},\n",
       "             'susquahana': {'thompson and susquahana'}})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Intersections aren't being fixed as they should be. Does it make a difference if they have 'Streets' at the end? \n",
    "audit(clean_full_osm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First version took 7 hours. Whew, only 8 min this time, after narrowing what fuzzy string match does. Stil, full file might take \n",
    "# 40 min or more. Now 6 min for 20% of file. w00t!\n",
    "fix_street_names(sample_file_k5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'206': {'US 70 and US 206'},\n",
       "             '33': {'Route 33'},\n",
       "             '70': {'NJ 70', 'US 70'},\n",
       "             '73': {'New Jersey 73'},\n",
       "             'NJ-73': {'NJ-73'},\n",
       "             'Vine': {'12th and Vine'}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Highways and intersections aren't consistent - are intersections valid addr:street attribute values? What format should state and \n",
    "# national highways follow?\n",
    "audit(sample_file_k5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Cleaned OSM XML to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import schema\n",
    "\n",
    "OSM_PATH = \"full_osm_clean.osm\"\n",
    "\n",
    "NODES_PATH = \"./db_csvs/nodes.csv\"\n",
    "NODE_TAGS_PATH = \"./db_csvs/node_tags.csv\"\n",
    "WAYS_PATH = \"./db_csvs/ways.csv\"\n",
    "WAY_NODES_PATH = \"./db_csvs/way_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"./db_csvs/way_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.schema\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  \n",
    "\n",
    "    for e in element.iter(\"tag\"):\n",
    "        id = element.get('id')\n",
    "        key = e.get('k')\n",
    "        value = e.get('v')\n",
    "        low = LOWER_COLON.search(key)\n",
    "        prob = PROBLEMCHARS.search(key)\n",
    "        if low and not prob:\n",
    "            kt = key.split(':', 1)\n",
    "            tags.append({\"id\": id, \"key\": kt[1], \"value\": value, \"type\": kt[0]})\n",
    "        if not low and not prob:\n",
    "            tags.append({\"id\": id, \"key\": key, \"value\": value, \"type\": 'regular'})\n",
    "        if prob:\n",
    "            continue\n",
    "        \n",
    "    if element.tag == 'node':\n",
    "        for idx, val in enumerate(NODE_FIELDS):\n",
    "            k = NODE_FIELDS[idx] \n",
    "            val = element.get(val)\n",
    "            node_attribs.update({k: val})    \n",
    "        if node_attribs:\n",
    "            return {'node': node_attribs, 'node_tags': tags}\n",
    "        else:\n",
    "            return None   \n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        for idx, val in enumerate(WAY_FIELDS):\n",
    "            k = WAY_FIELDS[idx]\n",
    "            val = element.get(val)\n",
    "            way_attribs.update({k: val})\n",
    "        i = 0\n",
    "        for w in element.iter('nd'):\n",
    "            id = element.get('id')\n",
    "            n_id = w.get('ref')\n",
    "            way_nodes.append({\"id\": id, \"node_id\": n_id, \"position\": i})\n",
    "            i += 1\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "    \n",
    "#     print node_attribs\n",
    "#     print way_attribs\n",
    "#     print way_nodes\n",
    "#     print tags\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "            \n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_strings = (\n",
    "            \"{0}: {1}\".format(k, v if isinstance(v, str) else \", \".join(v))\n",
    "            for k, v in errors.iteritems()\n",
    "        )\n",
    "        raise cerberus.ValidationError(\n",
    "            message_string.format(field, \"\\n\".join(error_strings))\n",
    "        )\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for element in get_element(OSM_PATH, tags=('node', 'way')):\n",
    "    x = shape_element(element)\n",
    "    print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 31 min with validator on 1/5 file\n",
    "import cerberus\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "    start_time = time.time()\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "    print(\"--- {}min ---\".format((time.time() - start_time)/60))\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "#     process_map(sample_file_k5, validate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "process_map(OSM_PATH, validate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SQL Database and Specify Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, ForeignKey, Column, Integer, Float, Date, String\n",
    "from sqlalchemy.orm import relationship, sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlite3 import dbapi2 as sqlite\n",
    "\n",
    "engine = create_engine('sqlite:///./db_csvs/philly_test_sql.db', module=sqlite)\n",
    "\n",
    "Base = declarative_base()\n",
    "\n",
    "class Node(Base):\n",
    "    __tablename__ = 'Nodes'\n",
    "    id = Column(Integer, primary_key=True, nullable=False) \n",
    "    lat = Column(Float)\n",
    "    lon = Column(Float)\n",
    "    user = Column(String)\n",
    "    uid = Column(Integer)\n",
    "    version = Column(String)\n",
    "    changeset = Column(Integer)\n",
    "    timestamp = Column(String)\n",
    "    \n",
    "class Node_Tag(Base):\n",
    "    __tablename__ = 'Node_Tags'\n",
    "    id = Column(Integer, ForeignKey(\"Nodes.id\"), nullable=False) \n",
    "    key = Column(String)\n",
    "    value = Column(String)\n",
    "    type = Column(String)\n",
    "    idx = Column(Integer, primary_key=True, index=True, unique=True, nullable=True)\n",
    "\n",
    "class Way(Base):\n",
    "    __tablename__ = 'Ways'\n",
    "    id = Column(Integer, primary_key=True, nullable=False) \n",
    "    user = Column(String)\n",
    "    uid = Column(Integer)\n",
    "    version = Column(String)\n",
    "    changeset = Column(Integer)\n",
    "    timestamp = Column(String)\n",
    "\n",
    "class Way_Node(Base):\n",
    "    __tablename__ = 'Way_Nodes'\n",
    "    id = Column(Integer, ForeignKey(\"Ways.id\"), nullable=False) \n",
    "    node_id = Column(Integer)\n",
    "    position = Column(Integer, nullable=True)\n",
    "    idx = Column(Integer, primary_key=True, index=True, unique=True, autoincrement=True)\n",
    "\n",
    "class Way_Tag(Base):\n",
    "    __tablename__ = 'Way_Tags'\n",
    "    id = Column(Integer, ForeignKey(\"Ways.id\"), nullable=False) \n",
    "    key = Column(String)\n",
    "    value = Column(String)\n",
    "    type = Column(String)\n",
    "    idx = Column(Integer, primary_key=True, index=True, unique=True, nullable=False)\n",
    "\n",
    "\n",
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from CSV Files and Write Records to SQL DB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "from time import time\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "def UnicodeDictReader(utf8_data, **kwargs):\n",
    "    csv_reader = csv.DictReader(utf8_data, **kwargs)\n",
    "    for row in csv_reader:\n",
    "        yield {key: unicode(value, 'utf-8') for key, value in row.iteritems()}\n",
    "\n",
    "def load_dat(filename):    \n",
    "    table_stem = filename.split('/')[2]\n",
    "    table_name = '_'.join([x.capitalize() for x in table_stem.split('_')]).strip('.csv')+'s'\n",
    "    \n",
    "    engine = create_engine('sqlite:///./db_csvs/philly_test_sql.db')\n",
    "    session = sessionmaker()\n",
    "    session.configure(bind=engine)\n",
    "    s = session()\n",
    "\n",
    "    with open(filename, 'rb') as f:\n",
    "        fiel = csv.DictReader(f)\n",
    "        fields = list(fiel)[0].keys()\n",
    "        n = len(fields)\n",
    "        if n == 8:\n",
    "            with open(filename, 'rb') as g:\n",
    "                fr = UnicodeDictReader(g)\n",
    "                dat = [{'id': i['id'], 'lat': i['lat'], 'lon': i['lat'], 'user': i['user'], 'uid': i['uid'], \n",
    "                        'version': i['version'], 'changeset': i['changeset'], 'timestamp': i['timestamp']} for i in fr]      \n",
    "            for row in dat:\n",
    "                record = Node(**row)\n",
    "                s.add(record)\n",
    "            s.commit()\n",
    "            s.close()    \n",
    "        if n == 6:\n",
    "            with open(filename, 'rb') as g:\n",
    "                fr = UnicodeDictReader(g)\n",
    "                dat = [{'id': i['id'], 'user': i['user'], 'uid': i['uid'], 'version': i['version'], 'changeset': i['changeset'],\n",
    "                        'timestamp': i['timestamp']} for i in fr]\n",
    "            for row in dat:\n",
    "                record = Way(**row)\n",
    "                s.add(record)\n",
    "            s.commit()\n",
    "            s.close()\n",
    "        if n == 4:\n",
    "            with open(filename, 'rb') as g:\n",
    "                fr = UnicodeDictReader(g)\n",
    "                dat = [{'id': i['id'], 'key': i['key'], 'value': i['value'], 'type': i['type']} for i in fr]       \n",
    "            for row in dat:\n",
    "                if table_name == 'Node_Tags':\n",
    "                    record = Node_Tag(**row)\n",
    "                    s.add(record)\n",
    "                if table_name == 'Way_Tags':\n",
    "                    record = Way_Tag(**row)\n",
    "                    s.add(record)\n",
    "            s.commit()\n",
    "            s.close\n",
    "        if n == 3:\n",
    "            with open(filename, 'rb') as g:\n",
    "                fr = UnicodeDictReader(g)\n",
    "                dat = [{'id': i['id'], 'node_id': i['node_id'], 'position': i['position']} for i in fr]\n",
    "            for row in dat:\n",
    "                record = Way_Node(**row)\n",
    "                s.add(record)\n",
    "            s.commit()\n",
    "            s.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Upload all CSV files in our directory to the SQL DB\n",
    "import fnmatch\n",
    "import os\n",
    "\n",
    "files = fnmatch.filter(os.listdir('./db_csvs'), '*.csv')\n",
    "\n",
    "for f in files:\n",
    "    fname = './db_csvs/{}'.format(f)\n",
    "    load_dat(fname) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test that the DB works and contains the expected tables and data\n",
    "import sqlite3\n",
    "conn = sqlite3.connect('./db_csvs/philly_test_sql.db')\n",
    "\n",
    "c = conn.cursor()\n",
    "\n",
    "x = c.execute(\"\"\"SELECT * FROM sqlite_master WHERE type='table';\"\"\")\n",
    "y = c.execute(\"\"\"SELECT count(*) FROM Nodes;\"\"\")\n",
    "\n",
    "print x.fetchall()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
